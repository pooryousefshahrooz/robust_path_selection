{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import os\n",
    "import ast\n",
    "import csv\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import time\n",
    "from pulp import LpMinimize, LpMaximize, LpProblem, LpStatus, lpSum, LpVariable, value, GLPK\n",
    "\n",
    "OBJ_EPSILON = 1e-12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "class Game(object):\n",
    "    def __init__(self, config, env, random_seed=1000):\n",
    "        self.random_state = np.random.RandomState(seed=random_seed)\n",
    " \n",
    "        self.data_dir = env.data_dir\n",
    "        self.DG = env.topology.DG\n",
    "        self.traffic_file = env.traffic_file\n",
    "        self.traffic_matrices = env.traffic_matrices\n",
    "        self.traffic_matrices_dims = self.traffic_matrices.shape\n",
    "        self.tm_cnt = env.tm_cnt\n",
    "        self.num_pairs = env.num_pairs\n",
    "        self.pair_idx_to_sd = env.pair_idx_to_sd\n",
    "        self.pair_sd_to_idx = env.pair_sd_to_idx\n",
    "        self.num_nodes = env.num_nodes\n",
    "        self.num_links = env.num_links\n",
    "        self.link_idx_to_sd = env.link_idx_to_sd\n",
    "        self.link_sd_to_idx = env.link_sd_to_idx\n",
    "        self.link_capacities = env.link_capacities\n",
    "        self.link_weights = env.link_weights\n",
    "        self.shortest_paths_node = env.shortest_paths_node              # paths with node info\n",
    "        self.shortest_paths_link = env.shortest_paths_link              # paths with link info\n",
    "\n",
    "        self.get_ecmp_next_hops()\n",
    "        \n",
    "        self.model_type = config.model_type\n",
    "        \n",
    "        #for LP\n",
    "        self.lp_pairs = [p for p in range(self.num_pairs)]\n",
    "        self.lp_nodes = [n for n in range(self.num_nodes)]\n",
    "        self.links = [e for e in range(self.num_links)]\n",
    "        self.lp_links = [e for e in self.link_sd_to_idx]\n",
    "        self.pair_links = [(pr, e[0], e[1]) for pr in self.lp_pairs for e in self.lp_links]\n",
    "\n",
    "        self.load_multiplier = {}\n",
    "        \n",
    "        \n",
    "        self.each_path_edges = {}\n",
    "        self.each_flow_paths = {}\n",
    "        self.each_flow_shortest_path ={}\n",
    "        self.each_path_id={}\n",
    "        self.each_id_path={}\n",
    "        \n",
    "        \n",
    "    def generate_inputs(self, normalization=True):\n",
    "        self.normalized_traffic_matrices = np.zeros((self.valid_tm_cnt, self.traffic_matrices_dims[1], self.traffic_matrices_dims[2], self.tm_history), dtype=np.float32)   #tm state  [Valid_tms, Node, Node, History]\n",
    "        idx_offset = self.tm_history - 1\n",
    "        for tm_idx in self.tm_indexes:\n",
    "            for h in range(self.tm_history):\n",
    "                if normalization:\n",
    "                    tm_max_element = np.max(self.traffic_matrices[tm_idx-h])\n",
    "                    self.normalized_traffic_matrices[tm_idx-idx_offset,:,:,h] = self.traffic_matrices[tm_idx-h] / tm_max_element        #[Valid_tms, Node, Node, History]\n",
    "                else:\n",
    "                    self.normalized_traffic_matrices[tm_idx-idx_offset,:,:,h] = self.traffic_matrices[tm_idx-h]                         #[Valid_tms, Node, Node, History]\n",
    "\n",
    "    def get_topK_flows(self, tm_idx, pairs):\n",
    "        tm = self.traffic_matrices[tm_idx]\n",
    "        f = {}\n",
    "        for p in pairs:\n",
    "            s, d = self.pair_idx_to_sd[p]\n",
    "            f[p] = tm[s][d]\n",
    "\n",
    "        sorted_f = sorted(f.items(), key = lambda kv: (kv[1], kv[0]), reverse=True)\n",
    "\n",
    "        cf = []\n",
    "        for i in range(self.max_moves):\n",
    "            cf.append(sorted_f[i][0])\n",
    "\n",
    "        return cf\n",
    "       \n",
    "    def get_ecmp_next_hops(self):\n",
    "        self.ecmp_next_hops = {}\n",
    "        for src in range(self.num_nodes):\n",
    "            for dst in range(self.num_nodes):\n",
    "                if src == dst:\n",
    "                    continue\n",
    "                self.ecmp_next_hops[src, dst] = []\n",
    "                for p in self.shortest_paths_node[self.pair_sd_to_idx[(src, dst)]]:\n",
    "                    if p[1] not in self.ecmp_next_hops[src, dst]:\n",
    "                        self.ecmp_next_hops[src, dst].append(p[1])\n",
    "\n",
    "    def ecmp_next_hop_distribution(self, link_loads, demand, src, dst):\n",
    "        if src == dst:\n",
    "            return\n",
    "\n",
    "        ecmp_next_hops = self.ecmp_next_hops[src, dst]\n",
    "\n",
    "        next_hops_cnt = len(ecmp_next_hops)\n",
    "        #if next_hops_cnt > 1:\n",
    "            #print(self.shortest_paths_node[self.pair_sd_to_idx[(src, dst)]])\n",
    "\n",
    "        ecmp_demand = demand / next_hops_cnt \n",
    "        for np in ecmp_next_hops:\n",
    "            link_loads[self.link_sd_to_idx[(src, np)]] += ecmp_demand\n",
    "            self.ecmp_next_hop_distribution(link_loads, ecmp_demand, np, dst)\n",
    "\n",
    "    def ecmp_traffic_distribution(self, tm_idx):\n",
    "        link_loads = np.zeros((self.num_links))\n",
    "        tm = self.traffic_matrices[tm_idx]\n",
    "        for pair_idx in range(self.num_pairs):\n",
    "            s, d = self.pair_idx_to_sd[pair_idx]\n",
    "            demand = tm[s][d]\n",
    "            if demand != 0:\n",
    "                self.ecmp_next_hop_distribution(link_loads, demand, s, d)\n",
    "\n",
    "        return link_loads\n",
    "\n",
    "    def get_critical_topK_flows(self, tm_idx, critical_links=5):\n",
    "        link_loads = self.ecmp_traffic_distribution(tm_idx)\n",
    "        critical_link_indexes = np.argsort(-(link_loads / self.link_capacities))[:critical_links]\n",
    "        \n",
    "        cf_potential = []\n",
    "        for pair_idx in range(self.num_pairs):\n",
    "            for path in self.shortest_paths_link[pair_idx]:\n",
    "                if len(set(path).intersection(critical_link_indexes)) > 0:\n",
    "                    cf_potential.append(pair_idx)\n",
    "                    break\n",
    "\n",
    "        #print(cf_potential)\n",
    "        assert len(cf_potential) >= self.max_moves,                 (\"cf_potential(%d) < max_move(%d), please increse critical_links(%d)\"%(cf_potential, self.max_moves, critical_links))\n",
    "\n",
    "        return self.get_topK_flows(tm_idx, cf_potential)\n",
    "    def eval_ecmp_traffic_distribution2(self, tm_idx, look_ahead_window,eval_delay=False):\n",
    "        mlus = []\n",
    "        for tm in range(tm_idx,tm_idx+look_ahead_window):\n",
    "            eval_link_loads = self.ecmp_traffic_distribution(tm)\n",
    "            eval_max_utilization = np.max(eval_link_loads / self.link_capacities)\n",
    "            self.load_multiplier[tm] = 0.9 / eval_max_utilization\n",
    "            mlus.append(eval_max_utilization)\n",
    "        \n",
    "            \n",
    "        return mlus        \n",
    "    def eval_ecmp_traffic_distribution(self, tm_idx, eval_delay=False):\n",
    "        eval_link_loads = self.ecmp_traffic_distribution(tm_idx)\n",
    "        eval_max_utilization = np.max(eval_link_loads / self.link_capacities)\n",
    "        self.load_multiplier[tm_idx] = 0.9 / eval_max_utilization\n",
    "        delay = 0\n",
    "        if eval_delay:\n",
    "            eval_link_loads *= self.load_multiplier[tm_idx]\n",
    "            delay = sum(eval_link_loads / (self.link_capacities - eval_link_loads))\n",
    "\n",
    "        return eval_max_utilization, delay\n",
    "    def optimal_routing_mlu_default(self, tm_idx):\n",
    "        tm = self.traffic_matrices[tm_idx]\n",
    "\n",
    "        demands = {}\n",
    "        \n",
    "\n",
    "        model = LpProblem(name=\"routing\")\n",
    "        #print('this %s is our self.pair_links' %(self.pair_links)) \n",
    "        ratio = LpVariable.dicts(name=\"ratio\", indexs=self.pair_links, lowBound=0, upBound=1)\n",
    "        #print(ratio)\n",
    "        link_load = LpVariable.dicts(name=\"link_load\", indexs=self.links)\n",
    "        #print(\"this %s is self.lp_links\"%(self.lp_links))\n",
    "        #print(\"this %s is self.lp_nodes\"%(self.lp_nodes))\n",
    "        #print(\"this %s is self.lp_pairs\"%(self.lp_pairs))\n",
    "        \"\"\"this will give MLU 0.5\"\"\"\n",
    "        each_flow_edges = {0:[(0,1)],1:[(0,2)],2:[(0,1),(1,3),(0,2),(2,3)],\n",
    "                          3:[(1,0)],4:[(1,0),(0,2)],5:[(1,3)],6:[(2,0)],\n",
    "                          7:[(2,0),(0,1)],8:[(2,3)],9:[(3,1),(1,0)],10:[(3,1)],11:[(3,2)]\n",
    "                          }\n",
    "        \"\"\"this will give MLU 1.0\"\"\"\n",
    "        each_flow_edges = {0: [(0, 1)],\n",
    "                           1: [(0, 2)], \n",
    "                           2: [(0, 1),(1,3),(0,2),(2,3)], \n",
    "                           3: [(1, 0)] ,\n",
    "                           4: [(1,0),(0, 2)], \n",
    "                           5: [(1, 3)],\n",
    "                           6: [(2,0)],\n",
    "                           7: [(2,0),(0 ,1)], \n",
    "                           8: [(2, 3)] ,\n",
    "                           9: [(3, 1),(1,0)], \n",
    "                           10: [(3,1)], \n",
    "                           11: [(3,2)] ,\n",
    "                           12: [(0,2),(2,4)] ,\n",
    "                           13: [(4,2),(2,0)] ,\n",
    "                           14: [(2, 4)] , \n",
    "                           15: [(4, 2)] , \n",
    "                           16: [(4, 2),(2,0),(0,1)] , \n",
    "                           17: [(4, 2),(2,3)] , \n",
    "                           18: [(1,0),(0, 2),(2,4)] , \n",
    "                           19: [(3, 2),(2,4)]\n",
    "                          }\n",
    "        r = LpVariable(name=\"congestion_ratio\")\n",
    "#         for pr in self.lp_pairs:\n",
    "#             for edge in self.lp_links:\n",
    "#                 #if (edge[0],edge[1]) not in each_flow_edges[pr]:\n",
    "#                 model +=(ratio[pr, edge[0], edge[1]] <=0.0)\n",
    "        \n",
    "        for pr in self.lp_pairs:\n",
    "#            print(\"for pr %s we add\"%(pr))\n",
    "            model += (lpSum([ratio[pr, e[0], e[1]] for e in self.lp_links if e[1] == self.pair_idx_to_sd[pr][0]]) - lpSum([ratio[pr, e[0], e[1]] for e in self.lp_links if e[0] == self.pair_idx_to_sd[pr][0]]) == -1 , \"flow_conservation_constr1_%d\"%pr)\n",
    "\n",
    "        for pr in self.lp_pairs:\n",
    "            model += (lpSum([ratio[pr, e[0], e[1]] for e in self.lp_links if e[1] == self.pair_idx_to_sd[pr][1]]) - lpSum([ratio[pr, e[0], e[1]] for e in self.lp_links if e[0] == self.pair_idx_to_sd[pr][1]]) == 1, \"flow_conservation_constr2_%d\"%pr)\n",
    "\n",
    "        for pr in self.lp_pairs:\n",
    "            for n in self.lp_nodes:\n",
    "                if n not in self.pair_idx_to_sd[pr]:\n",
    "                    model += (lpSum([ratio[pr, e[0], e[1]] for e in self.lp_links if e[1] == n]) - lpSum([ratio[pr, e[0], e[1]] for e in self.lp_links if e[0] == n]) == 0, \"flow_conservation_constr3_%d_%d\"%(pr,n))\n",
    "\n",
    "        for e in self.lp_links:\n",
    "            ei = self.link_sd_to_idx[e]\n",
    "            #print(\"for edge %s ei %s capacity is %s \"%(e,ei,self.link_capacities[ei]))\n",
    "            model += (link_load[ei] == lpSum([demands[pr]*ratio[pr, e[0], e[1]] for pr in self.lp_pairs]), \"link_load_constr%d\"%ei)\n",
    "            model += (link_load[ei] <= self.link_capacities[ei]*r, \"congestion_ratio_constr%d\"%ei)\n",
    "\n",
    "        model += r + OBJ_EPSILON*lpSum([link_load[e] for e in self.links])\n",
    "\n",
    "        model.solve(solver=GLPK(msg=False))\n",
    "        assert LpStatus[model.status] == 'Optimal'\n",
    "\n",
    "        obj_r = r.value()\n",
    "        solution = {}\n",
    "        for k in ratio:\n",
    "            solution[k] = ratio[k].value()\n",
    "\n",
    "        return obj_r, solution\n",
    "    def mlu_optimal_routing_mlu(self, tm_idx,look_ahead_window):\n",
    "        mlus= []\n",
    "        solutions = []\n",
    "        for traffic_m_indx in range(tm_idx,tm_idx+look_ahead_window-1):\n",
    "            tm = self.traffic_matrices[traffic_m_indx]\n",
    "\n",
    "            demands = {}\n",
    "            for i in range(self.num_pairs):\n",
    "                s, d = self.pair_idx_to_sd[i]\n",
    "                demands[i] = tm[s][d]\n",
    "                #print(\"demand from src %s to dst %s is %s\"%(s,d,demands[i])) \n",
    "\n",
    "            model = LpProblem(name=\"routing\")\n",
    "            #print('this %s is our self.pair_links' %(self.pair_links)) \n",
    "            ratio = LpVariable.dicts(name=\"ratio\", indexs=self.pair_links, lowBound=0, upBound=1)\n",
    "            #print(ratio)\n",
    "            link_load = LpVariable.dicts(name=\"link_load\", indexs=self.links)\n",
    "            #print(\"this %s is self.lp_links\"%(self.lp_links))\n",
    "            #print(\"this %s is self.lp_nodes\"%(self.lp_nodes))\n",
    "            #print(\"this %s is self.lp_pairs\"%(self.lp_pairs))\n",
    "            r = LpVariable(name=\"congestion_ratio\")\n",
    "    #         for pr in self.lp_pairs:\n",
    "    #             for edge in self.lp_links:\n",
    "    #                 if (edge[0],edge[1]) not in each_flow_edges[pr]:\n",
    "    #                     model +=(ratio[pr, edge[0], edge[1]] <=0.0)\n",
    "\n",
    "            for pr in self.lp_pairs:\n",
    "    #            print(\"for pr %s we add\"%(pr))\n",
    "                model += (lpSum([ratio[pr, e[0], e[1]] for e in self.lp_links if e[1] == self.pair_idx_to_sd[pr][0]]) - lpSum([ratio[pr, e[0], e[1]] for e in self.lp_links if e[0] == self.pair_idx_to_sd[pr][0]]) == -1 , \"flow_conservation_constr1_%d\"%pr)\n",
    "\n",
    "            for pr in self.lp_pairs:\n",
    "                model += (lpSum([ratio[pr, e[0], e[1]] for e in self.lp_links if e[1] == self.pair_idx_to_sd[pr][1]]) - lpSum([ratio[pr, e[0], e[1]] for e in self.lp_links if e[0] == self.pair_idx_to_sd[pr][1]]) == 1, \"flow_conservation_constr2_%d\"%pr)\n",
    "\n",
    "            for pr in self.lp_pairs:\n",
    "                for n in self.lp_nodes:\n",
    "                    if n not in self.pair_idx_to_sd[pr]:\n",
    "                        model += (lpSum([ratio[pr, e[0], e[1]] for e in self.lp_links if e[1] == n]) - lpSum([ratio[pr, e[0], e[1]] for e in self.lp_links if e[0] == n]) == 0, \"flow_conservation_constr3_%d_%d\"%(pr,n))\n",
    "\n",
    "            for e in self.lp_links:\n",
    "                ei = self.link_sd_to_idx[e]\n",
    "                #print(\"for edge %s ei %s capacity is %s \"%(e,ei,self.link_capacities[ei]))\n",
    "                model += (link_load[ei] == lpSum([demands[pr]*ratio[pr, e[0], e[1]] for pr in self.lp_pairs]), \"link_load_constr%d\"%ei)\n",
    "                model += (link_load[ei] <= self.link_capacities[ei]*r, \"congestion_ratio_constr%d\"%ei)\n",
    "\n",
    "            model += r + OBJ_EPSILON*lpSum([link_load[e] for e in self.links])\n",
    "\n",
    "            model.solve(solver=GLPK(msg=False))\n",
    "            assert LpStatus[model.status] == 'Optimal'\n",
    "\n",
    "            obj_r = r.value()\n",
    "            solution = {}\n",
    "            for k in ratio:\n",
    "                solution[k] = ratio[k].value()\n",
    "            mlu, optimal_mlu_delay = self.eval_optimal_routing_mlu(traffic_m_indx, solution, eval_delay=False)\n",
    "            mlus.append(mlu)\n",
    "            solutions.append(solution)\n",
    "        return mlus,solutions\n",
    "    def mlu_routing_selected_paths_oblivious2(self,tm_idx,look_ahead_window,each_flow_edges):\n",
    "        \n",
    "        #print(\"we check mlu for tm_idx\",tm_idx)\n",
    "        tm_mlu_using_suggested_paths = []\n",
    "        solutions = []\n",
    "        for traffic_m_indx in range(tm_idx,tm_idx+look_ahead_window-1):\n",
    "            #for k in each_flow_edges.keys():\n",
    "                #print('flow is ',k)\n",
    "            for i in range(self.num_pairs):\n",
    "                s, d = self.pair_idx_to_sd[i]\n",
    "                #print('flow is ',s,d)\n",
    "            #print('self.lp_pairs',self.lp_pairs)\n",
    "            #print(each_flow_edges)\n",
    "            import pdb\n",
    "            #pdb.set_trace()\n",
    "\n",
    "            #traffic_m_indx = tm_idx\n",
    "            tm = self.traffic_matrices[traffic_m_indx]\n",
    "\n",
    "            demands = {}\n",
    "            for i in range(self.num_pairs):\n",
    "                s, d = self.pair_idx_to_sd[i]\n",
    "                demands[i] = tm[s][d]\n",
    "                #demands[i] = 0\n",
    "                #print(\"demand from src %s to dst %s is %s\"%(s,d,demands[i])) \n",
    "\n",
    "            model = LpProblem(name=\"routing\")\n",
    "    #         print('this %s is our self.pair_links' %(self.pair_links)) \n",
    "            ratio = LpVariable.dicts(name=\"ratio\", indexs=self.pair_links, lowBound=0, upBound=1)\n",
    "            #print(ratio)\n",
    "            link_load = LpVariable.dicts(name=\"link_load\", indexs=self.links)\n",
    "    #         print(\"this %s is self.lp_links\"%(self.lp_links))\n",
    "    #         print(\"this %s is self.lp_nodes\"%(self.lp_nodes))\n",
    "    #         print(\"this %s is self.lp_pairs\"%(self.lp_pairs))\n",
    "            import pdb\n",
    "\n",
    "            r = LpVariable(name=\"congestion_ratio\")\n",
    "            for pr in self.lp_pairs:\n",
    "                s, d = self.pair_idx_to_sd[pr]\n",
    "                for edge in self.lp_links:\n",
    "                    if (edge[0],edge[1]) not in each_flow_edges[(s,d)]:\n",
    "                        model +=(ratio[pr, edge[0], edge[1]] ==0.0)\n",
    "\n",
    "            for pr in self.lp_pairs:\n",
    "    #            print(\"for pr %s we add\"%(pr))\n",
    "                #s, d = self.pair_idx_to_sd[pr]\n",
    "                model += (lpSum([ratio[pr, e[0], e[1]] \n",
    "                                 for e in self.lp_links if e[1] == self.pair_idx_to_sd[pr][0]]) - \n",
    "                          lpSum([ratio[pr, e[0], e[1]] \n",
    "                            for e in self.lp_links if e[0] == self.pair_idx_to_sd[pr][0]]) == -1 ,\n",
    "                          \"flow_conservation_constr1_%d\"%pr)\n",
    "\n",
    "            for pr in self.lp_pairs:\n",
    "                model += (lpSum([ratio[pr, e[0], e[1]] \n",
    "                        for e in self.lp_links if e[1] == self.pair_idx_to_sd[pr][1]]) -\n",
    "                        lpSum([ratio[pr, e[0], e[1]] \n",
    "                        for e in self.lp_links if e[0] == self.pair_idx_to_sd[pr][1]]) == 1,\n",
    "                          \"flow_conservation_constr2_%d\"%pr)\n",
    "\n",
    "            for pr in self.lp_pairs:\n",
    "                for n in self.lp_nodes:\n",
    "                    if n not in self.pair_idx_to_sd[pr]:\n",
    "                        model += (lpSum([ratio[pr, e[0], e[1]] \n",
    "                        for e in self.lp_links if e[1] == n]) -\n",
    "                        lpSum([ratio[pr, e[0], e[1]] for e in self.lp_links if e[0] == n]) == 0,\n",
    "                        \"flow_conservation_constr3_%d_%d\"%(pr,n))\n",
    "\n",
    "            for e in self.lp_links:\n",
    "                ei = self.link_sd_to_idx[e]\n",
    "                #print(\"for edge %s ei %s capacity is %s \"%(e,ei,self.link_capacities[ei]))\n",
    "                model += (link_load[ei] == lpSum([demands[pr]*ratio[pr, e[0], e[1]] \n",
    "                    for pr in self.lp_pairs]), \"link_load_constr%d\"%ei)\n",
    "\n",
    "                model += (link_load[ei] <= self.link_capacities[ei]*r, \"congestion_ratio_constr%d\"%ei)\n",
    "\n",
    "            model += r + OBJ_EPSILON*lpSum([link_load[e] for e in self.links])\n",
    "\n",
    "            model.solve(solver=GLPK(msg=False))\n",
    "            assert LpStatus[model.status] == 'Optimal'\n",
    "\n",
    "            obj_r = r.value()\n",
    "            solution = {}\n",
    "            for k in ratio:\n",
    "                solution[k] = ratio[k].value()\n",
    "        \n",
    "            tm = self.traffic_matrices[traffic_m_indx]\n",
    "            oblivious_mlu, oblivious_mlu_delay = self.eval_optimal_routing_mlu(traffic_m_indx, solution, eval_delay=False)\n",
    "            tm_mlu_using_suggested_paths.append(oblivious_mlu)\n",
    "            solutions.append(solution)\n",
    "            #print(\"******* we got the solution \",drl_mlu)\n",
    "        #return obj_r, solution \n",
    "        #print(\"here are the four mlu\",tm_mlu_using_suggested_paths)\n",
    "        return tm_mlu_using_suggested_paths,solutions\n",
    "    def mlu_routing_selected_paths_oblivious(self,tm_idx,look_ahead_window,each_flow_edges):\n",
    "        \n",
    "        tm_mlu_using_suggested_paths = []\n",
    "        solutions = []\n",
    "        #for k in each_flow_edges.keys():\n",
    "            #print('flow is ',k)\n",
    "        for i in range(self.num_pairs):\n",
    "            s, d = self.pair_idx_to_sd[i]\n",
    "            #print(\"these are the edges of flow %s %s \"%((s,d),each_flow_edges[(s,d)]))\n",
    "            #print('flow is ',s,d)\n",
    "        #print('self.lp_pairs',self.lp_pairs)\n",
    "        #print(each_flow_edges)\n",
    "        import pdb\n",
    "        #pdb.set_trace()\n",
    "        for traffic_m_indx in range(tm_idx,tm_idx+look_ahead_window-1):\n",
    "            tm = self.traffic_matrices[traffic_m_indx]\n",
    "\n",
    "            demands = {}\n",
    "            for i in range(self.num_pairs):\n",
    "                s, d = self.pair_idx_to_sd[i]\n",
    "                demands[i] = tm[s][d]\n",
    "                #demands[i] = 0\n",
    "                #print(\"demand from src %s to dst %s is %s\"%(s,d,demands[i])) \n",
    "\n",
    "            model = LpProblem(name=\"routing\")\n",
    "    #         print('this %s is our self.pair_links' %(self.pair_links)) \n",
    "            ratio = LpVariable.dicts(name=\"ratio\", indexs=self.pair_links, lowBound=0, upBound=1)\n",
    "            #print(ratio)\n",
    "            link_load = LpVariable.dicts(name=\"link_load\", indexs=self.links)\n",
    "    #         print(\"this %s is self.lp_links\"%(self.lp_links))\n",
    "    #         print(\"this %s is self.lp_nodes\"%(self.lp_nodes))\n",
    "    #         print(\"this %s is self.lp_pairs\"%(self.lp_pairs))\n",
    "            import pdb\n",
    "            \n",
    "            r = LpVariable(name=\"congestion_ratio\")\n",
    "            for pr in self.lp_pairs:\n",
    "                s, d = self.pair_idx_to_sd[pr]\n",
    "                for edge in self.lp_links:\n",
    "                    if (edge[0],edge[1]) not in each_flow_edges[(s,d)]:\n",
    "                        model +=(ratio[pr, edge[0], edge[1]] ==0.0)\n",
    "\n",
    "            for pr in self.lp_pairs:\n",
    "    #            print(\"for pr %s we add\"%(pr))\n",
    "                #s, d = self.pair_idx_to_sd[pr]\n",
    "                model += (lpSum([ratio[pr, e[0], e[1]] \n",
    "                                 for e in self.lp_links if e[1] == self.pair_idx_to_sd[pr][0]]) - \n",
    "                          lpSum([ratio[pr, e[0], e[1]] \n",
    "                            for e in self.lp_links if e[0] == self.pair_idx_to_sd[pr][0]]) == -1 ,\n",
    "                          \"flow_conservation_constr1_%d\"%pr)\n",
    "\n",
    "            for pr in self.lp_pairs:\n",
    "                model += (lpSum([ratio[pr, e[0], e[1]] \n",
    "                        for e in self.lp_links if e[1] == self.pair_idx_to_sd[pr][1]]) -\n",
    "                        lpSum([ratio[pr, e[0], e[1]] \n",
    "                        for e in self.lp_links if e[0] == self.pair_idx_to_sd[pr][1]]) == 1,\n",
    "                          \"flow_conservation_constr2_%d\"%pr)\n",
    "\n",
    "            for pr in self.lp_pairs:\n",
    "                for n in self.lp_nodes:\n",
    "                    if n not in self.pair_idx_to_sd[pr]:\n",
    "                        model += (lpSum([ratio[pr, e[0], e[1]] \n",
    "                        for e in self.lp_links if e[1] == n]) -\n",
    "                        lpSum([ratio[pr, e[0], e[1]] for e in self.lp_links if e[0] == n]) == 0,\n",
    "                        \"flow_conservation_constr3_%d_%d\"%(pr,n))\n",
    "\n",
    "            for e in self.lp_links:\n",
    "                ei = self.link_sd_to_idx[e]\n",
    "                #print(\"for edge %s ei %s capacity is %s \"%(e,ei,self.link_capacities[ei]))\n",
    "                model += (link_load[ei] == lpSum([demands[pr]*ratio[pr, e[0], e[1]] \n",
    "                    for pr in self.lp_pairs]), \"link_load_constr%d\"%ei)\n",
    "\n",
    "                model += (link_load[ei] <= self.link_capacities[ei]*r, \"congestion_ratio_constr%d\"%ei)\n",
    "\n",
    "            model += r + OBJ_EPSILON*lpSum([link_load[e] for e in self.links])\n",
    "\n",
    "            model.solve(solver=GLPK(msg=False))\n",
    "            assert LpStatus[model.status] == 'Optimal'\n",
    "\n",
    "            obj_r = r.value()\n",
    "            solution = {}\n",
    "            for k in ratio:\n",
    "                solution[k] = ratio[k].value()\n",
    "            drl_mlu, optimal_mlu_delay = self.eval_optimal_routing_mlu(traffic_m_indx, solution, eval_delay=False)\n",
    "            tm_mlu_using_suggested_paths.append(drl_mlu)\n",
    "            solutions.append(solution)\n",
    "            #print(\"******* we got the solution \",drl_mlu)\n",
    "        #return obj_r, solution \n",
    "        #print(\"here are the four mlu\",tm_mlu_using_suggested_paths)\n",
    "        return tm_mlu_using_suggested_paths,solutions\n",
    "    def optimal_solution_for_robust_paths(self,tm_idx,look_ahead_window):\n",
    "        #print(\"we check mlu for tm_idx\",tm_idx)\n",
    "        T= 0\n",
    "        R=0\n",
    "        all_paths = []\n",
    "        for path in self.each_path_edges:\n",
    "            if path not in all_paths:\n",
    "                all_paths.append(path)\n",
    "        for flow in self.lp_pairs:\n",
    "            R+=1 \n",
    "        R = max(R,self.max_moves)\n",
    "        for traffic_m_indx in range(tm_idx,tm_idx+look_ahead_window-1):\n",
    "            T+=1\n",
    "        all_flows = []\n",
    "        new_each_flow_paths = {}\n",
    "        for pr in self.lp_pairs:\n",
    "            s, d = self.pair_idx_to_sd[pr]\n",
    "            for path in self.each_flow_paths[(s,d)]:\n",
    "                try:\n",
    "                    new_each_flow_paths[pr].append(path)\n",
    "                except:\n",
    "                    new_each_flow_paths[pr]=[path]\n",
    "            all_flows.append(pr)\n",
    "#         for flow,paths in new_each_flow_paths.items():\n",
    "#             print(\"flow %s paths %s\"%(flow,paths))\n",
    "        each_flow_paths = {}\n",
    "        each_path_flow = {}\n",
    "        for f,paths in new_each_flow_paths.items():\n",
    "            each_flow_paths[f] = paths\n",
    "            for path in paths:\n",
    "                each_path_flow[path] = f\n",
    "        tm_mlu_using_suggested_paths = []\n",
    "        solutions = []\n",
    "\n",
    "        import pdb\n",
    "        #pdb.set_trace()\n",
    "        demands = {}\n",
    "        for traffic_m_indx in range(tm_idx,tm_idx+look_ahead_window-1):\n",
    "            tm = self.traffic_matrices[traffic_m_indx]\n",
    "            for i in range(self.num_pairs):\n",
    "                s, d = self.pair_idx_to_sd[i]\n",
    "                try:\n",
    "                    demands[traffic_m_indx][i] = tm[s][d]\n",
    "                except:\n",
    "                    demands[traffic_m_indx]={}\n",
    "                    demands[traffic_m_indx][i] = tm[s][d]\n",
    "                    \n",
    "                #demands[i] = 0\n",
    "                #print(\"demand from src %s to dst %s is %s\"%(s,d,demands[i])) \n",
    "        time_links_load_indexes = []\n",
    "        model = LpProblem(name=\"routing\")\n",
    "    #         print('this %s is our self.pair_links' %(self.pair_links)) \n",
    "        new_time_flow_paths_indexes = []\n",
    "        time_link_tracker_id = 0\n",
    "        each_t_link_index = {}\n",
    "        for traffic_m_indx in range(tm_idx,tm_idx+look_ahead_window-1):\n",
    "            #print(\"these are pair links\",self.pair_links)\n",
    "            for link in self.links:\n",
    "                time_links_load_indexes.append(time_link_tracker_id)\n",
    "                #print(\"key is %s trafic_mx_id %s link %s\"%((traffic_m_indx,link),traffic_m_indx,link))\n",
    "                each_t_link_index[(traffic_m_indx,link)] = time_link_tracker_id\n",
    "                time_link_tracker_id +=1\n",
    "            for pr,paths in each_flow_paths.items():\n",
    "                for path_id in paths:\n",
    "                    new_time_flow_paths_indexes.append((traffic_m_indx,pr,path_id))\n",
    "                #print(\"for time %s flow %s links are %s \"%(traffic_m_indx,flow_links))\n",
    "        import pdb\n",
    "        \n",
    "        ratio = LpVariable.dicts(name=\"ratio\", indexs=new_time_flow_paths_indexes, lowBound=0, upBound=1)\n",
    "        each_path_variable = LpVariable.dicts(name=\"pathflagh\", indexs=self.each_path_edges.keys(),cat=\"Integer\", lowBound=0, upBound=1)\n",
    "        #print(ratio)\n",
    "        \n",
    "        link_load = LpVariable.dicts(name=\"time_link_load\", indexs=time_links_load_indexes)\n",
    "#         print(\"this %s is self.lp_links\"%(self.lp_links))\n",
    "#         print(\"this %s is self.lp_nodes\"%(self.lp_nodes))\n",
    "#         print(\"this %s is self.lp_pairs\"%(self.lp_pairs))\n",
    "        import pdb\n",
    "        \n",
    "        r = LpVariable(name=\"congestion_ratio\")\n",
    "#         for traffic_m_indx in range(tm_idx,tm_idx+look_ahead_window-1):\n",
    "#             for pr in all_flows:\n",
    "#                 for path in each_flow_paths[pr]:\n",
    "#                 #for edge in self.lp_links:\n",
    "# #                     if (edge[0],edge[1]) not in each_flow_edges[(s,d)]:\n",
    "#                     if  each_path_variable[path] ==0:\n",
    "#                         model +=(ratio[traffic_m_indx,pr, path] ==0.0)\n",
    "        for traffic_m_indx in range(tm_idx,tm_idx+look_ahead_window-1):\n",
    "            for pr in self.lp_pairs:\n",
    "                s, d = self.pair_idx_to_sd[pr]\n",
    "                flow = (s,d)\n",
    "    #            print(\"for pr %s we add\"%(pr))\n",
    "                #s, d = self.pair_idx_to_sd[pr]\n",
    "                model += (lpSum([ratio[traffic_m_indx,pr, path] \n",
    "                                 for path in each_flow_paths[pr]]) == 1 ,\n",
    "                          \"flow_conservation_constr1_%d_%d\"%(traffic_m_indx,pr))\n",
    "        #print(\"the value of R is %s\"%(R))\n",
    "        model += (lpSum([each_path_variable[path] for path in all_paths]) == R,\"all_paths\")\n",
    "\n",
    "#         for pr in self.lp_pairs:\n",
    "#             for n in self.lp_nodes:\n",
    "#                 if n not in self.pair_idx_to_sd[pr]:\n",
    "#                     model += (lpSum([ratio[pr, e[0], e[1]] \n",
    "#                     for e in self.lp_links if e[1] == n]) -\n",
    "#                     lpSum([ratio[pr, e[0], e[1]] for e in self.lp_links if e[0] == n]) == 0,\n",
    "#                     \"flow_conservation_constr3_%d_%d\"%(pr,n))\n",
    "\n",
    "#         for e in self.lp_links:\n",
    "#             ei = self.link_sd_to_idx[e]\n",
    "#             print(\"e is %s and ei is %s \"%(e,ei))\n",
    "        for traffic_m_indx in range(tm_idx,tm_idx+look_ahead_window-1):\n",
    "            for e in self.lp_links:\n",
    "                ei = self.link_sd_to_idx[e]\n",
    "                #print(\"for edge %s ei %s capacity is %s \"%(e,ei,self.link_capacities[ei]))\n",
    "                #print(\"each_t_link_index \",each_t_link_index)\n",
    "                time_link_indx = each_t_link_index[(traffic_m_indx,ei)]\n",
    "#                 for pr in all_flows:\n",
    "#                     for path in each_flow_paths[pr]:\n",
    "#                         if e in each_path_edges[path]:\n",
    "#                             print(\"time %s time_link_indx %s edge %s,%s was in path %s for flow %s\"%(traffic_m_indx,time_link_indx,e,ei,each_path_edges[path],pr))\n",
    "#                         else:\n",
    "#                             print(\"time %s time_link_indx %s edge %s,%s was not in path %s for flow %s\"%(traffic_m_indx,time_link_indx,e,ei,each_path_edges[path],pr))\n",
    "#                         print(\"link load time link indx\",link_load[time_link_indx])\n",
    "                #print(\"thsi is link_load ***** \",link_load)\n",
    "    \n",
    "                model += (link_load[time_link_indx] == lpSum([demands[traffic_m_indx][pr]*ratio[traffic_m_indx,pr, path]\n",
    "                    for pr in all_flows  for path in each_flow_paths[pr] if (e in self.each_path_edges[path])]), \"link_load_constr%d_%d\"%(traffic_m_indx,ei))\n",
    "\n",
    "                model += (link_load[time_link_indx] <= self.link_capacities[ei]*r, \"congestion_ratio_constr%d\"%ei)\n",
    "\n",
    "        model += r + OBJ_EPSILON*lpSum([link_load[t_e] for t_e in time_links_load_indexes])/T\n",
    "\n",
    "        model.solve(solver=GLPK(msg=False))\n",
    "        assert LpStatus[model.status] == 'Optimal'\n",
    "\n",
    "        obj_r = r.value()\n",
    "        optimal_robust_paths = []\n",
    "        each_flow_robust_paths_edges={}\n",
    "        robust_path_counter = 0\n",
    "        \n",
    "        optimal_robust_paths = []\n",
    "        for traffic_m_indx in range(tm_idx,tm_idx+look_ahead_window-1):\n",
    "            for pr,paths in each_flow_paths.items():\n",
    "                rate_sum = 0\n",
    "                flow =  self.pair_idx_to_sd[pr]\n",
    "                for path_id in paths:\n",
    "                    rate_sum+= ratio[traffic_m_indx,pr, path_id].value()\n",
    "                    if ratio[traffic_m_indx,pr, path_id].value()>0:\n",
    "                        this_path_edges = self.each_path_edges[path_id]\n",
    "                        #print(\"for time %s flow %s path %s edges are %s\"%(traffic_m_indx,flow,path,this_path_edges))\n",
    "                        if path_id not in optimal_robust_paths:\n",
    "                            optimal_robust_paths.append(path_id)\n",
    "                        for edge in this_path_edges:\n",
    "                            try:\n",
    "                                if edge not in each_flow_robust_paths_edges[flow]:\n",
    "                                    each_flow_robust_paths_edges[flow].append(edge)\n",
    "                            except:\n",
    "                                try:\n",
    "                                    each_flow_robust_paths_edges[flow].append(edge)\n",
    "                                except:\n",
    "                                    each_flow_robust_paths_edges[flow]=[edge]\n",
    "                    \n",
    "                    \n",
    "                    \n",
    "                    \n",
    "#                 print(\"1: at time %s for flow %s the sum of rates of all paths is %s\"%(traffic_m_indx,pr,rate_sum))     \n",
    "                          \n",
    "              \n",
    "        \n",
    "#         for traffic_m_indx in range(tm_idx,tm_idx+look_ahead_window-1):\n",
    "#             for pr in self.lp_pairs:\n",
    "#                 s, d = self.pair_idx_to_sd[pr]\n",
    "#                 flow = (s,d)\n",
    "#                 rate_sum  = 0\n",
    "#                 for path in each_flow_paths[pr]:\n",
    "#                     if each_path_variable[path].value()==1:\n",
    "#                         rate_sum = rate_sum+ratio[traffic_m_indx,pr, path].value() \n",
    "#                         this_path_edges = each_path_edges[path]\n",
    "#                         #print(\"for time %s flow %s path %s edges are %s\"%(traffic_m_indx,flow,path,this_path_edges))\n",
    "#                         if path not in optimal_robust_paths:\n",
    "#                             optimal_robust_paths.append(path)\n",
    "#                         for edge in this_path_edges:\n",
    "#                             try:\n",
    "#                                 if edge not in each_flow_robust_paths_edges[flow]:\n",
    "#                                     each_flow_robust_paths_edges[flow].append(edge)\n",
    "#                             except:\n",
    "#                                 try:\n",
    "#                                     each_flow_robust_paths_edges[flow].append(edge)\n",
    "#                                 except:\n",
    "#                                     each_flow_robust_paths_edges[flow]=[edge]\n",
    "#                 print(\"at time %s for flow %s the sum of rates of all paths is %s\"%(traffic_m_indx,flow,rate_sum))\n",
    "                                  \n",
    "        import pdb\n",
    "        \n",
    "#         for pr,paths in each_flow_paths.items():\n",
    "#             flow = self.pair_idx_to_sd[pr]\n",
    "#             if flow not in each_flow_robust_paths_edges:\n",
    "#                 print(\"we do not have even one path for flow!!!! \",flow)\n",
    "        #print(\"selected path numbers \",len(optimal_robust_paths))\n",
    "        #for traffic_m_indx in range(tm_idx,tm_idx+look_ahead_window-1):\n",
    "            #print(\"time is \",traffic_m_indx)\n",
    "        #print(each_flow_robust_paths_edges)\n",
    "        #print(each_flow_robust_paths_edges[(0,1)])\n",
    "        #pdb.set_trace()\n",
    "        optimal_mlus,optimal_solutions = self.mlu_routing_selected_paths(tm_idx,look_ahead_window,\n",
    "                                                               each_flow_robust_paths_edges)\n",
    "        \n",
    "        \n",
    "        for traffic_m_indx in range(tm_idx,tm_idx+look_ahead_window-1):\n",
    "            solution = {}\n",
    "            for k in ratio:\n",
    "                \n",
    "                #print(ratio)\n",
    "                time_of_key  = k[0]\n",
    "                #print(\"This is traffic indx %s and k is %s and time of key is %s\"%(traffic_m_indx,k,time_of_key))\n",
    "                if time_of_key==traffic_m_indx:\n",
    "                    solution[k] = ratio[k].value()\n",
    "            optimal_mlu, optimal_mlu_delay = self.eval_optimal_robust_paths_routing_mlu(traffic_m_indx, solution, each_flow_paths,eval_delay=False)\n",
    "            #print(\"we got the mlu %s for time %s \"%(optimal_mlu,traffic_m_indx))\n",
    "            tm_mlu_using_suggested_paths.append(optimal_mlu)\n",
    "            solutions.append(solution)\n",
    "            #pdb.set_trace()\n",
    "        #print(\"******* we got the solution \",drl_mlu)\n",
    "        #return obj_r, solution \n",
    "        #print(\"here are the four mlu\",tm_mlu_using_suggested_paths)\n",
    "        #print(\"mlu using robust paths without hashing %s and with rehashing %s\"%\n",
    "#               (sum(optimal_mlus)/len(optimal_mlus),sum(tm_mlu_using_suggested_paths)/len(tm_mlu_using_suggested_paths)))\n",
    "#         return tm_mlu_using_suggested_paths,solutions\n",
    "        number_of_selected_paths = 0\n",
    "        for path in all_paths:\n",
    "            number_of_selected_paths+= each_path_variable[path].value()\n",
    "        optimal_robust_paths.sort()\n",
    "#         for path in optimal_robust_paths:\n",
    "#             print(\"for optimal we have %s their flag %s path %s \"%(len(optimal_robust_paths),number_of_selected_paths,path))\n",
    "        #return optimal_mlus,optimal_solutions,tm_mlu_using_suggested_paths,solutions\n",
    "        return optimal_mlus,optimal_solutions,optimal_mlus,optimal_solutions\n",
    "        if sum(optimal_mlus)/len(optimal_mlus)<sum(tm_mlu_using_suggested_paths)/len(tm_mlu_using_suggested_paths):\n",
    "            return optimal_mlus,optimal_solutions\n",
    "        else:\n",
    "            return tm_mlu_using_suggested_paths,solutions\n",
    "        \n",
    "    def mlu_routing_selected_paths(self,tm_idx,look_ahead_window,each_flow_edges):\n",
    "        #print(\"we check mlu for tm_idx\",tm_idx)\n",
    "        tm_mlu_using_suggested_paths = []\n",
    "        solutions = []\n",
    "        #for k in each_flow_edges.keys():\n",
    "            #print('flow is ',k)\n",
    "        for i in range(self.num_pairs):\n",
    "            s, d = self.pair_idx_to_sd[i]\n",
    "            #print(\"these are the edges of flow %s %s \"%((s,d),each_flow_edges[(s,d)]))\n",
    "            #print('flow is ',s,d)\n",
    "        #print('self.lp_pairs',self.lp_pairs)\n",
    "        #print(each_flow_edges)\n",
    "        import pdb\n",
    "        #pdb.set_trace()\n",
    "        for traffic_m_indx in range(tm_idx,tm_idx+look_ahead_window-1):\n",
    "            tm = self.traffic_matrices[traffic_m_indx]\n",
    "\n",
    "            demands = {}\n",
    "            for i in range(self.num_pairs):\n",
    "                s, d = self.pair_idx_to_sd[i]\n",
    "                demands[i] = tm[s][d]\n",
    "                #demands[i] = 0\n",
    "                #print(\"demand from src %s to dst %s is %s\"%(s,d,demands[i])) \n",
    "\n",
    "            model = LpProblem(name=\"routing\")\n",
    "    #         print('this %s is our self.pair_links' %(self.pair_links)) \n",
    "            ratio = LpVariable.dicts(name=\"ratio\", indexs=self.pair_links, lowBound=0, upBound=1)\n",
    "            #print(ratio)\n",
    "            link_load = LpVariable.dicts(name=\"link_load\", indexs=self.links)\n",
    "    #         print(\"this %s is self.lp_links\"%(self.lp_links))\n",
    "    #         print(\"this %s is self.lp_nodes\"%(self.lp_nodes))\n",
    "    #         print(\"this %s is self.lp_pairs\"%(self.lp_pairs))\n",
    "            import pdb\n",
    "            \n",
    "            r = LpVariable(name=\"congestion_ratio\")\n",
    "            for pr in self.lp_pairs:\n",
    "                s, d = self.pair_idx_to_sd[pr]\n",
    "                for edge in self.lp_links:\n",
    "                    if (edge[0],edge[1]) not in each_flow_edges[(s,d)]:\n",
    "                        model +=(ratio[pr, edge[0], edge[1]] ==0.0)\n",
    "\n",
    "            for pr in self.lp_pairs:\n",
    "    #            print(\"for pr %s we add\"%(pr))\n",
    "                #s, d = self.pair_idx_to_sd[pr]\n",
    "                model += (lpSum([ratio[pr, e[0], e[1]] \n",
    "                                 for e in self.lp_links if e[1] == self.pair_idx_to_sd[pr][0]]) - \n",
    "                          lpSum([ratio[pr, e[0], e[1]] \n",
    "                            for e in self.lp_links if e[0] == self.pair_idx_to_sd[pr][0]]) == -1 ,\n",
    "                          \"flow_conservation_constr1_%d\"%pr)\n",
    "\n",
    "            for pr in self.lp_pairs:\n",
    "                model += (lpSum([ratio[pr, e[0], e[1]] \n",
    "                        for e in self.lp_links if e[1] == self.pair_idx_to_sd[pr][1]]) -\n",
    "                        lpSum([ratio[pr, e[0], e[1]] \n",
    "                        for e in self.lp_links if e[0] == self.pair_idx_to_sd[pr][1]]) == 1,\n",
    "                          \"flow_conservation_constr2_%d\"%pr)\n",
    "\n",
    "            for pr in self.lp_pairs:\n",
    "                for n in self.lp_nodes:\n",
    "                    if n not in self.pair_idx_to_sd[pr]:\n",
    "                        model += (lpSum([ratio[pr, e[0], e[1]] \n",
    "                        for e in self.lp_links if e[1] == n]) -\n",
    "                        lpSum([ratio[pr, e[0], e[1]] for e in self.lp_links if e[0] == n]) == 0,\n",
    "                        \"flow_conservation_constr3_%d_%d\"%(pr,n))\n",
    "\n",
    "            for e in self.lp_links:\n",
    "                ei = self.link_sd_to_idx[e]\n",
    "                #print(\"for edge %s ei %s capacity is %s \"%(e,ei,self.link_capacities[ei]))\n",
    "                model += (link_load[ei] == lpSum([demands[pr]*ratio[pr, e[0], e[1]] \n",
    "                    for pr in self.lp_pairs]), \"link_load_constr%d\"%ei)\n",
    "\n",
    "                model += (link_load[ei] <= self.link_capacities[ei]*r, \"congestion_ratio_constr%d\"%ei)\n",
    "\n",
    "            model += r + OBJ_EPSILON*lpSum([link_load[e] for e in self.links])\n",
    "\n",
    "            model.solve(solver=GLPK(msg=False))\n",
    "            assert LpStatus[model.status] == 'Optimal'\n",
    "\n",
    "            obj_r = r.value()\n",
    "            solution = {}\n",
    "            for k in ratio:\n",
    "                solution[k] = ratio[k].value()\n",
    "            drl_mlu, optimal_mlu_delay = self.eval_optimal_routing_mlu(traffic_m_indx, solution, eval_delay=False)\n",
    "            tm_mlu_using_suggested_paths.append(drl_mlu)\n",
    "            solutions.append(solution)\n",
    "            #print(\"******* we got the solution \",drl_mlu)\n",
    "        #return obj_r, solution \n",
    "        #print(\"here are the four mlu\",tm_mlu_using_suggested_paths)\n",
    "        return tm_mlu_using_suggested_paths,solutions\n",
    "    def eval_optimal_robust_paths_routing_mlu(self,tm_idx, solution,each_flow_paths, eval_delay=False):\n",
    "        optimal_link_loads = np.zeros((self.num_links))\n",
    "        eval_tm = self.traffic_matrices[tm_idx]\n",
    "        for i in range(self.num_pairs):\n",
    "            s, d = self.pair_idx_to_sd[i]\n",
    "            demand = eval_tm[s][d]\n",
    "            for e in self.lp_links:\n",
    "                link_idx = self.link_sd_to_idx[e]\n",
    "                for path in each_flow_paths[i]:\n",
    "                    if e in self.each_path_edges[path]:\n",
    "                        #print(\"for src %s dst %s  e %s we have demand %s and solution %s \"%(s,d,e,demand,solution[i, e[0], e[1]]))\n",
    "                        optimal_link_loads[link_idx] += demand*solution[tm_idx,i, path]\n",
    "        \n",
    "        optimal_max_utilization = np.max(optimal_link_loads / self.link_capacities)\n",
    "        \n",
    "        delay = 0\n",
    "        return optimal_max_utilization,delay\n",
    "    def eval_optimal_routing_mlu(self, tm_idx, solution, eval_delay=False):\n",
    "        optimal_link_loads = np.zeros((self.num_links))\n",
    "        eval_tm = self.traffic_matrices[tm_idx]\n",
    "        for i in range(self.num_pairs):\n",
    "            s, d = self.pair_idx_to_sd[i]\n",
    "            demand = eval_tm[s][d]\n",
    "            for e in self.lp_links:\n",
    "                link_idx = self.link_sd_to_idx[e]\n",
    "                #print(\"for src %s dst %s  e %s we have demand %s and solution %s \"%(s,d,e,demand,solution[i, e[0], e[1]]))\n",
    "                optimal_link_loads[link_idx] += demand*solution[i, e[0], e[1]]\n",
    "        \n",
    "        optimal_max_utilization = np.max(optimal_link_loads / self.link_capacities)\n",
    "        delay = 0\n",
    "        if eval_delay:\n",
    "            assert tm_idx in self.load_multiplier, (tm_idx)\n",
    "            optimal_link_loads *= self.load_multiplier[tm_idx]\n",
    "            delay = sum(optimal_link_loads / (self.link_capacities - optimal_link_loads))\n",
    "                        \n",
    "        return optimal_max_utilization, delay\n",
    "\n",
    "    def optimal_routing_mlu_critical_pairs(self, tm_idx, critical_pairs):\n",
    "        tm = self.traffic_matrices[tm_idx]\n",
    "\n",
    "        pairs = critical_pairs\n",
    "\n",
    "        demands = {}\n",
    "        background_link_loads = np.zeros((self.num_links))\n",
    "        for i in range(self.num_pairs):\n",
    "            s, d = self.pair_idx_to_sd[i]\n",
    "            #background link load\n",
    "            if i not in critical_pairs:\n",
    "                self.ecmp_next_hop_distribution(background_link_loads, tm[s][d], s, d)\n",
    "            else:\n",
    "                demands[i] = tm[s][d]\n",
    "\n",
    "        model = LpProblem(name=\"routing\")\n",
    "        \n",
    "        pair_links = [(pr, e[0], e[1]) for pr in pairs for e in self.lp_links] \n",
    "        ratio = LpVariable.dicts(name=\"ratio\", indexs=pair_links, lowBound=0, upBound=1)\n",
    "        \n",
    "        link_load = LpVariable.dicts(name=\"link_load\", indexs=self.links)\n",
    "\n",
    "        r = LpVariable(name=\"congestion_ratio\")\n",
    "\n",
    "        for pr in pairs:\n",
    "            model += (lpSum([ratio[pr, e[0], e[1]] for e in self.lp_links if e[1] == self.pair_idx_to_sd[pr][0]]) - lpSum([ratio[pr, e[0], e[1]] for e in self.lp_links if e[0] == self.pair_idx_to_sd[pr][0]]) == -1, \"flow_conservation_constr1_%d\"%pr)\n",
    "\n",
    "        for pr in pairs:\n",
    "            model += (lpSum([ratio[pr, e[0], e[1]] for e in self.lp_links if e[1] == self.pair_idx_to_sd[pr][1]]) - lpSum([ratio[pr, e[0], e[1]] for e in self.lp_links if e[0] == self.pair_idx_to_sd[pr][1]]) == 1, \"flow_conservation_constr2_%d\"%pr)\n",
    "\n",
    "        for pr in pairs:\n",
    "            for n in self.lp_nodes:\n",
    "                if n not in self.pair_idx_to_sd[pr]:\n",
    "                    model += (lpSum([ratio[pr, e[0], e[1]] for e in self.lp_links if e[1] == n]) - lpSum([ratio[pr, e[0], e[1]] for e in self.lp_links if e[0] == n]) == 0, \"flow_conservation_constr3_%d_%d\"%(pr,n))\n",
    "\n",
    "        for e in self.lp_links:\n",
    "            ei = self.link_sd_to_idx[e]\n",
    "            model += (link_load[ei] == background_link_loads[ei] + lpSum([demands[pr]*ratio[pr, e[0], e[1]] for pr in pairs]), \"link_load_constr%d\"%ei)\n",
    "            model += (link_load[ei] <= self.link_capacities[ei]*r, \"congestion_ratio_constr%d\"%ei)\n",
    "\n",
    "        model += r + OBJ_EPSILON*lpSum([link_load[ei] for ei in self.links])\n",
    "\n",
    "        model.solve(solver=GLPK(msg=False))\n",
    "        assert LpStatus[model.status] == 'Optimal'\n",
    "\n",
    "        obj_r = r.value()\n",
    "        solution = {}\n",
    "        for k in ratio:\n",
    "            solution[k] = ratio[k].value()\n",
    "\n",
    "        return obj_r, solution\n",
    "\n",
    "    def eval_critical_flow_and_ecmp(self, tm_idx, critical_pairs, solution, eval_delay=False):\n",
    "        eval_tm = self.traffic_matrices[tm_idx]\n",
    "        eval_link_loads = np.zeros((self.num_links))\n",
    "        for i in range(self.num_pairs):\n",
    "            s, d = self.pair_idx_to_sd[i]\n",
    "            if i not in critical_pairs:\n",
    "                self.ecmp_next_hop_distribution(eval_link_loads, eval_tm[s][d], s, d)\n",
    "            else:\n",
    "                demand = eval_tm[s][d]\n",
    "                for e in self.lp_links:\n",
    "                    link_idx = self.link_sd_to_idx[e]\n",
    "                    eval_link_loads[link_idx] += eval_tm[s][d]*solution[i, e[0], e[1]]\n",
    "\n",
    "        eval_max_utilization = np.max(eval_link_loads / self.link_capacities)\n",
    "        delay = 0\n",
    "        if eval_delay:\n",
    "            assert tm_idx in self.load_multiplier, (tm_idx)\n",
    "            eval_link_loads *= self.load_multiplier[tm_idx]\n",
    "            delay = sum(eval_link_loads / (self.link_capacities - eval_link_loads))\n",
    "        \n",
    "        return eval_max_utilization, delay\n",
    "\n",
    "    def optimal_routing_delay(self, tm_idx):\n",
    "        assert tm_idx in self.load_multiplier, (tm_idx)\n",
    "        tm = self.traffic_matrices[tm_idx]*self.load_multiplier[tm_idx]\n",
    "        demands = {}\n",
    "        for i in range(self.num_pairs):\n",
    "            s, d = self.pair_idx_to_sd[i]\n",
    "            demands[i] = tm[s][d]\n",
    "\n",
    "        model = LpProblem(name=\"routing\")\n",
    "     \n",
    "        ratio = LpVariable.dicts(name=\"ratio\", indexs=self.pair_links, lowBound=0, upBound=1)\n",
    "\n",
    "        link_load = LpVariable.dicts(name=\"link_load\", indexs=self.links)\n",
    "\n",
    "        f = LpVariable.dicts(name=\"link_cost\", indexs=self.links)\n",
    "\n",
    "        for pr in self.lp_pairs:\n",
    "            model += (lpSum([ratio[pr, e[0], e[1]] for e in self.lp_links if e[1] == self.pair_idx_to_sd[pr][0]]) - lpSum([ratio[pr, e[0], e[1]] for e in self.lp_links if e[0] == self.pair_idx_to_sd[pr][0]]) == -1, \"flow_conservation_constr1_%d\"%pr)\n",
    "\n",
    "        for pr in self.lp_pairs:\n",
    "            model += (lpSum([ratio[pr, e[0], e[1]] for e in self.lp_links if e[1] == self.pair_idx_to_sd[pr][1]]) - lpSum([ratio[pr, e[0], e[1]] for e in self.lp_links if e[0] == self.pair_idx_to_sd[pr][1]]) == 1, \"flow_conservation_constr2_%d\"%pr)\n",
    "\n",
    "        for pr in self.lp_pairs:\n",
    "            for n in self.lp_nodes:\n",
    "                if n not in self.pair_idx_to_sd[pr]:\n",
    "                    model += (lpSum([ratio[pr, e[0], e[1]] for e in self.lp_links if e[1] == n]) - lpSum([ratio[pr, e[0], e[1]] for e in self.lp_links if e[0] == n]) == 0, \"flow_conservation_constr3_%d_%d\"%(pr,n))\n",
    "\n",
    "        for e in self.lp_links:\n",
    "            ei = self.link_sd_to_idx[e]\n",
    "            model += (link_load[ei] == lpSum([demands[pr]*ratio[pr, e[0], e[1]] for pr in self.lp_pairs]), \"link_load_constr%d\"%ei)\n",
    "            model += (f[ei] * self.link_capacities[ei] >= link_load[ei], \"cost_constr1_%d\"%ei)\n",
    "            model += (f[ei] >= 3 * link_load[ei] / self.link_capacities[ei] - 2/3, \"cost_constr2_%d\"%ei)\n",
    "            model += (f[ei] >= 10 * link_load[ei] / self.link_capacities[ei] - 16/3, \"cost_constr3_%d\"%ei)\n",
    "            model += (f[ei] >= 70 * link_load[ei] / self.link_capacities[ei] - 178/3, \"cost_constr4_%d\"%ei)\n",
    "            model += (f[ei] >= 500 * link_load[ei] / self.link_capacities[ei] - 1468/3, \"cost_constr5_%d\"%ei)\n",
    "            model += (f[ei] >= 5000 * link_load[ei] / self.link_capacities[ei] - 16318/3, \"cost_constr6_%d\"%ei)\n",
    "       \n",
    "        model += lpSum(f[ei] for ei in self.links)\n",
    "\n",
    "        model.solve(solver=GLPK(msg=False))\n",
    "        assert LpStatus[model.status] == 'Optimal'\n",
    "\n",
    "        solution = {}\n",
    "        for k in ratio:\n",
    "            solution[k] = ratio[k].value()\n",
    "\n",
    "        return solution\n",
    "\n",
    "    def eval_optimal_routing_delay(self, tm_idx, solution):\n",
    "        optimal_link_loads = np.zeros((self.num_links))\n",
    "        assert tm_idx in self.load_multiplier, (tm_idx)\n",
    "        eval_tm = self.traffic_matrices[tm_idx]*self.load_multiplier[tm_idx]\n",
    "        for i in range(self.num_pairs):\n",
    "            s, d = self.pair_idx_to_sd[i]\n",
    "            demand = eval_tm[s][d]\n",
    "            for e in self.lp_links:\n",
    "                link_idx = self.link_sd_to_idx[e]\n",
    "                optimal_link_loads[link_idx] += demand*solution[i, e[0], e[1]]\n",
    "        \n",
    "        optimal_delay = sum(optimal_link_loads / (self.link_capacities - optimal_link_loads))\n",
    "\n",
    "        return optimal_delay\n",
    "    def get_suggested_paths_by_rl(self,actions):\n",
    "        \n",
    "        for flow,paths in self.each_flow_paths.items():\n",
    "            covered_flow = False\n",
    "            for path_id in paths:\n",
    "                #path_id = self.each_path_id[path]\n",
    "                if not covered_flow:\n",
    "                    if path_id in actions:\n",
    "                        covered_flow =True \n",
    "            if not covered_flow:\n",
    "                #print(\"flow  did not have any candidate path in chosen paths\",flow)\n",
    "                flow_shortest_path = self.each_flow_shortest_path[flow]\n",
    "                #print(flow_shortest_path)\n",
    "                #print(each_path_id)\n",
    "                path_id = self.each_path_id[tuple(flow_shortest_path)]\n",
    "\n",
    "                actions = np.append(actions, path_id)\n",
    "#         print(\"these are the paths of flow \",self.each_flow_paths[(0,4)])\n",
    "#         for flow in self.each_flow_paths:\n",
    "#             if flow not in self.each_flow_shortest_path:\n",
    "#                 print(\"the flow %s does not have a shortest path!!!!\"%(flow))\n",
    "        each_flow_edges = {}\n",
    "        for flow in self.each_flow_shortest_path:\n",
    "            #print(\"for flow \",flow)\n",
    "            for path in actions:\n",
    "                #path = each_id_path[path_id]\n",
    "                if path in self.each_flow_paths[flow]:\n",
    "                    #print(\"we are going to add these edges \",path_id,path)\n",
    "                    path_edges = self.each_path_edges[path]\n",
    "                    for edge in path_edges:\n",
    "                        try:\n",
    "                            if edge not in each_flow_edges[flow]:\n",
    "                                each_flow_edges[flow].append(edge)\n",
    "                                each_flow_edges[flow].append((edge[1],edge[0]))\n",
    "                        except:\n",
    "                            each_flow_edges[flow]=[edge]\n",
    "                            each_flow_edges[flow].append((edge[1],edge[0]))\n",
    "        return each_flow_edges\n",
    "    \n",
    "    def get_set_of_all_paths(self,tm_idx,look_ahead_window,each_flow_paths,each_path_id,each_id_path,each_flow_shortest_path,each_flow_oblivious_paths,topology_file,config):\n",
    "        target_times = []\n",
    "        each_flow_paths2 = {}\n",
    "        for flow,paths in each_flow_paths.items():\n",
    "            each_flow_paths2[flow] = list(paths)\n",
    "        \n",
    "        for flow,path in each_flow_shortest_path.items():\n",
    "            #print(\"these are shortest paths \",paths)\n",
    "            path = tuple(path)\n",
    "            if path not in each_flow_paths2[flow]:\n",
    "                each_flow_paths[flow].add(path)\n",
    "        \n",
    "#         for flow,paths in each_flow_oblivious_paths.items():\n",
    "            \n",
    "#             for path in paths:\n",
    "# #                 path = tuple(path)\n",
    "#                 path = path[0]\n",
    "                \n",
    "#                 if path not in each_flow_paths2[flow]:\n",
    "#                     each_flow_paths[flow].add(path)\n",
    "        \"\"\"we now add the edges for each flow from the selected actions\"\"\"\n",
    "        each_path_edges = {}\n",
    "        for flow,paths in each_flow_paths2.items():\n",
    "            for path in paths:\n",
    "                path_id = each_path_id[path]\n",
    "                for node_indx in range(len(path)-1):\n",
    "                    try:\n",
    "                        if (path[node_indx],path[node_indx+1]) not in each_path_edges[path_id]:\n",
    "                            each_path_edges[path_id].append((path[node_indx],path[node_indx+1]))\n",
    "                            each_path_edges[path_id].append((path[node_indx+1],path[node_indx]))\n",
    "                    except:\n",
    "                        each_path_edges[path_id]=[(path[node_indx],path[node_indx+1])]\n",
    "                        each_path_edges[path_id].append((path[node_indx+1],path[node_indx]))\n",
    "        \n",
    "#         for flow,edges in each_flow_edges.items():\n",
    "#             print(\"this flow %s has these edges %s\"%(flow,edges))\n",
    "#         print(\"and this is our max moves\",self.max_moves)\n",
    "        new_each_flow_paths = {}\n",
    "        for flow,paths in each_flow_paths2.items():\n",
    "            new_paths = []\n",
    "            for path in paths:\n",
    "                path_id = each_path_id[path]\n",
    "                new_paths.append(path_id)\n",
    "            new_each_flow_paths[flow] = new_paths\n",
    "        return new_each_flow_paths,each_path_edges\n",
    "    def get_hindsight_set_of_paths(self,tm_idx,look_ahead_window,each_flow_paths,each_path_id,each_id_path,each_flow_shortest_path,topology_file,config):\n",
    "        target_times = []\n",
    "        for t in range(tm_idx,tm_idx+look_ahead_window):\n",
    "            target_times.append(t)\n",
    "        each_path_counter = {}\n",
    "        #print('topology is ',topology_file)\n",
    "        with open(config.each_topology_each_t_each_f_paths) as file:\n",
    "            lines = file.readlines()\n",
    "            for line in lines:\n",
    "                if topology_file in line:#ATT_topology_file_modified:189:1->20: ['1', '13', '9', '4', '20'],['1', '9', '4', '20']\n",
    "                    time = line.split(\":\")[1]\n",
    "                    if int(time) in target_times:\n",
    "                        flow_str = line.split(\":\")[2]\n",
    "                        flow = flow_str.split(\"->\")\n",
    "                        flow = (int(flow[0]),int(flow[1]))\n",
    "                        paths = line.split(flow_str+\":\")[1]\n",
    "                        paths = paths.strip()\n",
    "                        paths = \"\\\"\"+str(paths)+\"\\\"\"\n",
    "                        paths = ast.literal_eval(paths)\n",
    "                        #print('time %s flow %s paths %s'%(time,flow, paths))\n",
    "                        #print(type(paths),len(paths))\n",
    "                        if '],[' in paths:\n",
    "                            paths = ast.literal_eval(paths)\n",
    "                        else:\n",
    "                            paths = ast.literal_eval(paths)\n",
    "                            new_path = []\n",
    "                            for p in paths:\n",
    "                                new_path.append(p)\n",
    "                            paths = [new_path]\n",
    "                        #print('2time %s flow %s paths %s'%(time,flow, paths))\n",
    "                        #print(type(paths),len(paths))\n",
    "                        for p in paths:\n",
    "                            p = tuple(p)\n",
    "                            new_p= []\n",
    "                            for node in p:\n",
    "                                new_p.append(int(node))\n",
    "                            p = tuple(new_p)\n",
    "                            try:\n",
    "                                each_path_counter[p]+=1\n",
    "                            except:\n",
    "                                each_path_counter[p]=1\n",
    "        repeated_times = []\n",
    "        for path,counter in   each_path_counter.items():\n",
    "            if counter not in repeated_times:\n",
    "                repeated_times.append(counter)\n",
    "        repeated_times.sort()\n",
    "        top_selected_path_ids = []\n",
    "        top_selected_counters = repeated_times[-self.max_moves:]\n",
    "        for p,counter in each_path_counter.items():\n",
    "            if counter in top_selected_counters:\n",
    "                if len(top_selected_path_ids)<self.max_moves:\n",
    "                    path_id = each_path_id[p]\n",
    "                    top_selected_path_ids.append(path_id)\n",
    "        \n",
    "        for flow,paths in each_flow_paths.items():\n",
    "            covered_flow = False\n",
    "            for path in paths:\n",
    "                path_id = each_path_id[path]\n",
    "                if not covered_flow:\n",
    "                    if path_id in top_selected_path_ids:\n",
    "                        covered_flow =True \n",
    "            if not covered_flow:\n",
    "                #print(\"flow  did not have any candidate path in chosen paths\",flow)\n",
    "                flow_shortest_path = each_flow_shortest_path[flow]\n",
    "                #print(flow_shortest_path)\n",
    "                #print(each_path_id)\n",
    "                path_id = self.each_path_id[tuple(flow_shortest_path)]\n",
    "                \n",
    "                top_selected_path_ids.append(path_id)\n",
    "                #print(\"we added path id %s for safety\"%(path_id))\n",
    "        \n",
    "        \"\"\"end of safe online learning section\"\"\"\n",
    "        \n",
    "#         for path_id in actions:\n",
    "#             print(\"we have chosen and safed action %s %s\"%(path_id,len(actions)))\n",
    "            \n",
    "        each_flow_selected_paths = {}\n",
    "        \"\"\"we now add the edges for each flow from the selected actions\"\"\"\n",
    "        each_flow_edges = {}\n",
    "        for flow in each_flow_shortest_path:\n",
    "            for path_id in top_selected_path_ids:\n",
    "                path = each_id_path[path_id]\n",
    "                if path in each_flow_paths[flow]:\n",
    "                    try:\n",
    "                        each_flow_selected_paths[flow].append(path)\n",
    "                    except:\n",
    "                        each_flow_selected_paths[flow]=[path]\n",
    "                    for node_indx in range(len(path)-1):\n",
    "                        try:\n",
    "                            if (path[node_indx],path[node_indx+1]) not in each_flow_edges[flow]:\n",
    "                                each_flow_edges[flow].append((path[node_indx],path[node_indx+1]))\n",
    "                                each_flow_edges[flow].append((path[node_indx+1],path[node_indx]))\n",
    "                        except:\n",
    "                            each_flow_edges[flow]=[(path[node_indx],path[node_indx+1])]\n",
    "                            each_flow_edges[flow].append((path[node_indx+1],path[node_indx]))\n",
    "        \n",
    "#         for flow,edges in each_flow_edges.items():\n",
    "#             print(\"this flow %s has these edges %s\"%(flow,edges))\n",
    "#         print(\"and this is our max moves\",self.max_moves)\n",
    "        return each_flow_edges\n",
    "# In[ ]:\n",
    "    def set_paths_info(self,env,topology_name,each_topology_each_t_each_f_paths):\n",
    "    \n",
    "        self.each_path_edges = {}\n",
    "        self.each_flow_paths = {}\n",
    "        self.each_flow_shortest_path ={}\n",
    "        self.each_path_id={}\n",
    "        self.each_id_path={}\n",
    "        all_the_paths = set([])\n",
    "        each_t_paths = {}\n",
    "        #print('topology is ',topology_name)\n",
    "        with open(each_topology_each_t_each_f_paths) as file:\n",
    "            lines = file.readlines()\n",
    "            for line in lines:\n",
    "                if topology_name in line:#ATT_topology_file_modified:189:1->20: ['1', '13', '9', '4', '20'],['1', '9', '4', '20']\n",
    "                    time = line.split(\":\")[1]\n",
    "                    flow_str = line.split(\":\")[2]\n",
    "                    flow = flow_str.split(\"->\")\n",
    "                    flow = (int(flow[0]),int(flow[1]))\n",
    "                    paths = line.split(flow_str+\":\")[1]\n",
    "                    paths = paths.strip()\n",
    "                    paths = \"\\\"\"+str(paths)+\"\\\"\"\n",
    "                    paths = ast.literal_eval(paths)\n",
    "                    #print('time %s flow %s paths %s'%(time,flow, paths))\n",
    "                    #print(type(paths),len(paths))\n",
    "                    if '],[' in paths:\n",
    "                        paths = ast.literal_eval(paths)\n",
    "                    else:\n",
    "                        paths = ast.literal_eval(paths)\n",
    "                        new_path = []\n",
    "                        for p in paths:\n",
    "                            new_path.append(p)\n",
    "                        paths = [new_path]\n",
    "                    #print('2time %s flow %s paths %s'%(time,flow, paths))\n",
    "                    #print(type(paths),len(paths))\n",
    "                    for p in paths:\n",
    "                        p = tuple(p)\n",
    "                        new_p= []\n",
    "                        for node in p:\n",
    "                            new_p.append(int(node))\n",
    "                        p = tuple(new_p)\n",
    "\n",
    "                        try:\n",
    "                            each_t_paths[time].add(p)\n",
    "                        except:\n",
    "                            each_t_paths[time] = set([p])\n",
    "                        all_the_paths.add(p)\n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "        path_counter = 0\n",
    "        each_path_id = {}\n",
    "        set_of_times = set([])\n",
    "        each_flow_path_usage = {}\n",
    "        all_the_paths = set([])\n",
    "        each_t_paths = {}\n",
    "        each_flow_paths = {}\n",
    "        #print('topology is ',topology_name)\n",
    "        with open(each_topology_each_t_each_f_paths) as file:\n",
    "            lines = file.readlines()\n",
    "            for line in lines:\n",
    "                if topology_name in line:#ATT_topology_file_modified:189:1->20: ['1', '13', '9', '4', '20'],['1', '9', '4', '20']\n",
    "                    time = line.split(\":\")[1]\n",
    "                    flow_str = line.split(\":\")[2]\n",
    "                    flow = flow_str.split(\"->\")\n",
    "                    flow = (int(flow[0]),int(flow[1]))\n",
    "                    set_of_times.add(time)\n",
    "                    paths = line.split(flow_str+\":\")[1]\n",
    "                    paths = paths.strip()\n",
    "                    paths = \"\\\"\"+str(paths)+\"\\\"\"\n",
    "                    paths = ast.literal_eval(paths)\n",
    "                    #print('time %s flow %s paths %s'%(time,flow, paths))\n",
    "                    #print(type(paths),len(paths))\n",
    "                    if '],[' in paths:\n",
    "                        paths = ast.literal_eval(paths)\n",
    "                    else:\n",
    "                        paths = ast.literal_eval(paths)\n",
    "                        new_path = []\n",
    "                        for p in paths:\n",
    "                            new_path.append(p)\n",
    "                        paths = [new_path]\n",
    "                    #print('2time %s flow %s paths %s'%(time,flow, paths))\n",
    "                    #print(type(paths),len(paths))\n",
    "                    for p in paths:\n",
    "                        p = tuple(p)\n",
    "                        new_p= []\n",
    "                        for node in p:\n",
    "                            new_p.append(int(node))\n",
    "                        p = tuple(new_p)\n",
    "                        try:\n",
    "                            each_t_paths[time].add(p)\n",
    "                        except:\n",
    "                            each_t_paths[time] = set([p])\n",
    "                            \n",
    "                        try:\n",
    "                            each_flow_paths[flow].add(p)\n",
    "                        except:\n",
    "                            each_flow_paths[flow] =set([p])\n",
    "                        try:\n",
    "                            each_t_paths[time].add(p)\n",
    "                        except:\n",
    "                            each_t_paths[time] = set([p])\n",
    "                        all_the_paths.add(p)\n",
    "                        #print('this is a path ',p)\n",
    "                        \n",
    "                        \n",
    "        paths_number = []\n",
    "        for time, paths in each_t_paths.items():\n",
    "            #print('for time %s we had %s paths'%(time,len(paths)))\n",
    "            paths_number.append(len(paths))\n",
    "        avg_paths_per_time = int((sum(paths_number)/len(paths_number)))\n",
    "        \n",
    "        each_path_id = {}\n",
    "        id_counter = 0\n",
    "        each_id_path = {}\n",
    "        covered_paths = []\n",
    "        for flow,paths in each_flow_paths.items():\n",
    "            for p in paths:\n",
    "                #print(\"theis was path \",p)\n",
    "                covered_paths.append(tuple(p))\n",
    "                self.each_path_id[tuple(p)] = id_counter\n",
    "                self.each_id_path[id_counter] = tuple(p)\n",
    "                id_counter+=1\n",
    "        self.each_flow_shortest_path = env.topology.get_each_flow_shortest_paths()\n",
    "        for flow,paths in self.each_flow_shortest_path.items():\n",
    "            \n",
    "            #print(\"this is the path \",tuple(paths))\n",
    "            if tuple(paths) not in covered_paths:\n",
    "                each_flow_paths[flow].add(tuple(paths))\n",
    "                covered_paths.append(tuple(paths))\n",
    "                self.each_path_id[tuple(paths)] = id_counter\n",
    "                self.each_id_path[id_counter] = tuple(paths)\n",
    "                id_counter+=1\n",
    "        \n",
    "        \n",
    "        for flow, paths in each_flow_paths.items():\n",
    "            for path in paths:\n",
    "                path_id = self.each_path_id[path]\n",
    "                try:\n",
    "                    self.each_flow_paths[flow].add(path_id)\n",
    "                except:\n",
    "                    self.each_flow_paths[flow]=set([path_id])\n",
    "                for node_indx in range(len(path)-1):\n",
    "                    try:\n",
    "                        if (path[node_indx],path[node_indx+1]) not in self.each_path_edges[path_id]:\n",
    "                            self.each_path_edges[path_id].append((path[node_indx],path[node_indx+1]))\n",
    "                            self.each_path_edges[path_id].append((path[node_indx+1],path[node_indx]))\n",
    "                    except:\n",
    "                        self.each_path_edges[path_id]=[(path[node_indx],path[node_indx+1])]\n",
    "                        self.each_path_edges[path_id].append((path[node_indx+1],path[node_indx]))\n",
    "                \n",
    "        \n",
    "    def get_each_flow_paths_and_path_id(self,env,config,topology_name):\n",
    "        \"\"\"in this function, we get the B=4 most used paths by each flow\n",
    "\n",
    "        we get all the used path by each flow over all times and get top 4 of them\"\"\"\n",
    "        path_counter = 0\n",
    "        each_path_id = {}\n",
    "        set_of_times = set([])\n",
    "        each_flow_path_usage = {}\n",
    "        all_the_paths = set([])\n",
    "        each_t_paths = {}\n",
    "        each_flow_paths = {}\n",
    "        #print('topology is ',topology_name)\n",
    "        with open(config.each_topology_each_t_each_f_paths) as file:\n",
    "            lines = file.readlines()\n",
    "            for line in lines:\n",
    "                if topology_name in line:#ATT_topology_file_modified:189:1->20: ['1', '13', '9', '4', '20'],['1', '9', '4', '20']\n",
    "                    time = line.split(\":\")[1]\n",
    "                    flow_str = line.split(\":\")[2]\n",
    "                    flow = flow_str.split(\"->\")\n",
    "                    flow = (int(flow[0]),int(flow[1]))\n",
    "                    set_of_times.add(time)\n",
    "                    paths = line.split(flow_str+\":\")[1]\n",
    "                    paths = paths.strip()\n",
    "                    paths = \"\\\"\"+str(paths)+\"\\\"\"\n",
    "                    paths = ast.literal_eval(paths)\n",
    "                    #print('time %s flow %s paths %s'%(time,flow, paths))\n",
    "                    #print(type(paths),len(paths))\n",
    "                    if '],[' in paths:\n",
    "                        paths = ast.literal_eval(paths)\n",
    "                    else:\n",
    "                        paths = ast.literal_eval(paths)\n",
    "                        new_path = []\n",
    "                        for p in paths:\n",
    "                            new_path.append(p)\n",
    "                        paths = [new_path]\n",
    "                    #print('2time %s flow %s paths %s'%(time,flow, paths))\n",
    "                    #print(type(paths),len(paths))\n",
    "                    for p in paths:\n",
    "                        p = tuple(p)\n",
    "                        new_p= []\n",
    "                        for node in p:\n",
    "                            new_p.append(int(node))\n",
    "                        p = tuple(new_p)\n",
    "                        try:\n",
    "                            each_flow_paths[flow].add(p)\n",
    "                        except:\n",
    "                            each_flow_paths[flow] =set([p])\n",
    "                        try:\n",
    "                            each_t_paths[time].add(p)\n",
    "                        except:\n",
    "                            each_t_paths[time] = set([p])\n",
    "                        all_the_paths.add(p)\n",
    "                        #print('this is a path ',p)\n",
    "        each_path_id = {}\n",
    "        id_counter = 0\n",
    "        each_id_path = {}\n",
    "        covered_paths = []\n",
    "        for flow,paths in each_flow_paths.items():\n",
    "            for p in paths:\n",
    "                #print(\"theis was path \",p)\n",
    "                covered_paths.append(tuple(p))\n",
    "                each_path_id[tuple(p)] = id_counter\n",
    "                each_id_path[id_counter] = tuple(p)\n",
    "                id_counter+=1\n",
    "        each_flow_shortest_paths = env.topology.get_each_flow_shortest_paths()\n",
    "        for flow,paths in each_flow_shortest_paths.items():\n",
    "            \n",
    "            #print(\"this is the path \",tuple(paths))\n",
    "            if tuple(paths) not in covered_paths:\n",
    "                covered_paths.append(tuple(paths))\n",
    "                each_path_id[tuple(paths)] = id_counter\n",
    "                each_id_path[id_counter] = tuple(paths)\n",
    "                id_counter+=1\n",
    "        return each_flow_paths,each_path_id,each_id_path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class CFRRL_Game(Game):\n",
    "    def __init__(self, config, env,commitment_window,look_ahead_window,path_counter,avg_paths_per_t, random_seed=1000):\n",
    "        super(CFRRL_Game, self).__init__(config, env, random_seed)\n",
    "        \n",
    "        self.project_name = config.project_name\n",
    "        #env.num_pairs = self.num_pairs\n",
    "        self.action_dim = path_counter\n",
    "        #print(\"self.action_dim is %s path_counter is %s \"%(self.action_dim,path_counter))\n",
    "        self.max_moves = int(self.action_dim * (config.max_moves / 100.))\n",
    "        self.max_moves = avg_paths_per_t\n",
    "        #print(\"self.max_moves %s self.action_dim %s self.max_moves %s self.action_dim %s\"\n",
    "       #       %(self.max_moves , self.action_dim, self.max_moves, self.action_dim))\n",
    "        #assert self.max_moves <= self.action_dim, (self.max_moves, self.action_dim)\n",
    "        \n",
    "        self.tm_history = 1\n",
    "        self.tm_history=commitment_window\n",
    "        self.tm_indexes = np.arange(self.tm_history-1, self.tm_cnt)\n",
    "        self.valid_tm_cnt = len(self.tm_indexes)\n",
    "        \n",
    "        if config.method == 'pure_policy':\n",
    "            self.baseline = {}\n",
    "\n",
    "        self.generate_inputs(normalization=True)\n",
    "        self.state_dims = self.normalized_traffic_matrices.shape[1:]\n",
    "        print('Input dims :', self.state_dims)\n",
    "        print('Max moves :', self.max_moves)\n",
    "        import pdb\n",
    "        print('whole shapes ',self.normalized_traffic_matrices.shape)\n",
    "        print('avg_paths_per_t',avg_paths_per_t)\n",
    "        #pdb.set_trace()\n",
    "        \"\"\"two new variables\"\"\"\n",
    "        \n",
    "        self.commitment_window =commitment_window\n",
    "        self.look_ahead_window = look_ahead_window\n",
    "\n",
    "    def get_state(self, tm_idx):\n",
    "        idx_offset = self.tm_history - 1\n",
    "        return self.normalized_traffic_matrices[tm_idx-idx_offset]\n",
    "    def reward2(self, tm_idx,all_tms,look_ahead_window,each_flow_edges,topology_file,printing_flag):\n",
    "        \n",
    "#         _, solution = self.optimal_routing_mlu(tm_idx)\n",
    "#         optimal_mlu, optimal_mlu_delay = self.eval_optimal_routing_mlu(tm_idx, solution, eval_delay=False)\n",
    "#         print(\"here is the optimal mlu\",optimal_mlu)\n",
    "#         _, solution = self.optimal_routing_mlu_default(tm_idx)\n",
    "#         optimal_mlu, optimal_mlu_delay = self.eval_optimal_routing_mlu(tm_idx, solution, eval_delay=False)\n",
    "#         print(\"here is the optimal mlu 2\",optimal_mlu)\n",
    "#         mlu, _ = self.optimal_routing_mlu_critical_pairs(tm_idx, actions)\n",
    "        \n",
    "#         print(\"here is the optimal mlu using critical flow rerouting\",optimal_mlu)\n",
    "        \n",
    "        drl_mlus,solutions = self.mlu_routing_selected_paths(tm_idx,look_ahead_window,each_flow_edges)\n",
    "        drl_mlu = sum(drl_mlus)/len(drl_mlus)\n",
    "        #print(\"this is the avg mlu using the suggested paths \",drl_mlu)\n",
    "        \n",
    "        #each_flow_edges_hindsight_approach = self.get_hindsight_set_of_paths(tm_idx,look_ahead_window,each_flow_paths,each_path_id,each_id_path,each_flow_shortest_path,topology_file)\n",
    "        #hindsight_mlu = self.mlu_routing_selected_paths(tm_idx,look_ahead_window,each_flow_edges_hindsight_approach)\n",
    "        mlu_optimal_mlus,mlu_optimal_solutions = self.mlu_optimal_routing_mlu(tm_idx,look_ahead_window)\n",
    "        mlu_optimal_mlu = sum(mlu_optimal_mlus)/len(mlu_optimal_mlus)\n",
    "        reward = mlu_optimal_mlu/drl_mlu\n",
    "        if printing_flag:\n",
    "            print(\"for tm_idx point %s from %s rl is %s mlu optimal approach is %s and the reward is %s\"%(tm_idx,all_tms,drl_mlu,mlu_optimal_mlu,reward))\n",
    "        return reward\n",
    "        import pdb\n",
    "        pdb.set_trace()\n",
    "        optimal_mlu = self.get_optimal_avg_mlu_hindsight(tm_idx,look_ahead_window)\n",
    "        \n",
    "    def reward(self, tm_idx, actions):\n",
    "        mlu, _ = self.optimal_routing_mlu_critical_pairs(tm_idx, actions)\n",
    "\n",
    "        reward = 1 / mlu\n",
    "\n",
    "        return reward\n",
    "    def get_all_trainig_epochs(self,commitment_window,look_ahead_window):\n",
    "        indx = 1\n",
    "        epochs = []\n",
    "        epochs.append(1)\n",
    "        epochs.append(9)\n",
    "        while(max(epochs)<509):\n",
    "            epochs.append(max(epochs)+50)\n",
    "        while(max(epochs)<2999):\n",
    "            epochs.append(max(epochs)+400)\n",
    "        \n",
    "        \n",
    "        return list(epochs)\n",
    "    def advantage(self, tm_idx, reward):\n",
    "        if tm_idx not in self.baseline:\n",
    "            return reward\n",
    "\n",
    "        total_v, cnt = self.baseline[tm_idx]\n",
    "        \n",
    "        #print(reward, (total_v/cnt))\n",
    "\n",
    "        return reward - (total_v/cnt)\n",
    "\n",
    "    def update_baseline(self, tm_idx, reward):\n",
    "        if tm_idx in self.baseline:\n",
    "            total_v, cnt = self.baseline[tm_idx]\n",
    "\n",
    "            total_v += reward\n",
    "            cnt += 1\n",
    "\n",
    "            self.baseline[tm_idx] = (total_v, cnt)\n",
    "        else:\n",
    "            self.baseline[tm_idx] = (reward, 1)\n",
    "\n",
    "    def evaluate(self, tm_idx, actions=None, ecmp=True, eval_delay=False):\n",
    "        \n",
    "        _, solution = self.optimal_routing_mlu(tm_idx)\n",
    "        optimal_mlu, optimal_mlu_delay = self.eval_optimal_routing_mlu(tm_idx, solution, eval_delay=eval_delay)\n",
    "        #print(\"for tm_idx %s we have mlu %s\"%(tm_idx,optimal_mlu))\n",
    "        if ecmp:\n",
    "            ecmp_mlu, ecmp_delay = self.eval_ecmp_traffic_distribution(tm_idx, eval_delay=eval_delay)\n",
    "        \n",
    "        _, solution = self.optimal_routing_mlu_critical_pairs(tm_idx, actions)\n",
    "        mlu, delay = self.eval_critical_flow_and_ecmp(tm_idx, actions, solution, eval_delay=eval_delay)\n",
    "\n",
    "        crit_topk = self.get_critical_topK_flows(tm_idx)\n",
    "        _, solution = self.optimal_routing_mlu_critical_pairs(tm_idx, crit_topk)\n",
    "        crit_mlu, crit_delay = self.eval_critical_flow_and_ecmp(tm_idx, crit_topk, solution, eval_delay=eval_delay)\n",
    "\n",
    "        topk = self.get_topK_flows(tm_idx, self.lp_pairs)\n",
    "        _, solution = self.optimal_routing_mlu_critical_pairs(tm_idx, topk)\n",
    "        topk_mlu, topk_delay = self.eval_critical_flow_and_ecmp(tm_idx, topk, solution, eval_delay=eval_delay)\n",
    "\n",
    "\n",
    "        norm_mlu = optimal_mlu / mlu\n",
    "        line = str(tm_idx) + ', ' + str(norm_mlu) + ', ' + str(mlu) + ', ' \n",
    "        \n",
    "        norm_crit_mlu = optimal_mlu / crit_mlu\n",
    "        line += str(norm_crit_mlu) + ', ' + str(crit_mlu) + ', ' \n",
    "\n",
    "        norm_topk_mlu = optimal_mlu / topk_mlu\n",
    "        line += str(norm_topk_mlu) + ', ' + str(topk_mlu) + ', ' \n",
    "\n",
    "        if ecmp:\n",
    "            norm_ecmp_mlu = optimal_mlu / ecmp_mlu\n",
    "            line += str(norm_ecmp_mlu) + ', ' + str(ecmp_mlu) + ', '\n",
    "\n",
    "        if eval_delay:\n",
    "            solution = self.optimal_routing_delay(tm_idx)\n",
    "            optimal_delay = self.eval_optimal_routing_delay(tm_idx, solution) \n",
    "\n",
    "            line += str(optimal_delay/delay) + ', ' \n",
    "            line += str(optimal_delay/crit_delay) + ', ' \n",
    "            line += str(optimal_delay/topk_delay) + ', ' \n",
    "            line += str(optimal_delay/optimal_mlu_delay) + ', '\n",
    "            if ecmp:\n",
    "                line += str(optimal_delay/ecmp_delay) + ', '\n",
    "        \n",
    "            assert tm_idx in self.load_multiplier, (tm_idx)\n",
    "            line += str(self.load_multiplier[tm_idx]) + ', '\n",
    "\n",
    "        print(line[:-2])\n",
    "        \n",
    "    \n",
    "        \n",
    "        \n",
    "        \n",
    "    def evaluate3(self, env,config,tm_idx,all_tms,training_epoch,commitment_window, look_ahead_window,topology_file,actions=None, ecmp=True, eval_delay=False):\n",
    "        toplogy_t_solution_mlu_result = config.testing_results\n",
    "        time_index = tm_idx\n",
    "        each_flow_oblivious_paths = env.topology.get_each_flow_oblivious_paths(config.raeke_paths)\n",
    "        each_flow_shortest_path = env.topology.get_each_flow_shortest_paths()\n",
    "        each_flow_paths,each_path_id,each_id_path = self.get_each_flow_paths_and_path_id(env,config,topology_file)\n",
    "        each_flow_all_paths,each_path_edges = self.get_set_of_all_paths(tm_idx,\n",
    "                                                                             look_ahead_window,each_flow_paths,\n",
    "                                                                             each_path_id,each_id_path,\n",
    "                                                                             each_flow_shortest_path,each_flow_oblivious_paths,\n",
    "                                                                             topology_file,config)\n",
    "        \n",
    "        hindsight_mlus,hindsight_solutions = self.optimal_solution_for_robust_paths(tm_idx,look_ahead_window,\n",
    "                                                                             each_flow_all_paths,each_path_edges)\n",
    "        \n",
    "        \n",
    "    def evaluate2(self, env,config,tm_idx,all_tms,commitment_window, look_ahead_window,topology_file,scheme,max_move,actions=None, ecmp=True, eval_delay=False):\n",
    "        \n",
    "#         toplogy_t_solution_mlu_result = config.testing_results\n",
    "#         time_index = tm_idx\n",
    "#         each_flow_shortest_path = env.topology.get_each_flow_shortest_paths()\n",
    "#         each_flow_paths,each_path_id,each_id_path = self.get_each_flow_paths_and_path_id(topology_file)\n",
    "#         each_flow_edges_hindsight_approach = self.get_hindsight_set_of_paths(tm_idx,\n",
    "#                                                                              look_ahead_window,each_flow_paths,\n",
    "#                                                                              each_path_id,each_id_path,\n",
    "#                                                                              each_flow_shortest_path,topology_file,config)\n",
    "        \n",
    "#         hindsight_mlus,hindsight_solutions = self.mlu_routing_selected_paths(tm_idx,look_ahead_window,\n",
    "#       each_flow_edges_hindsight_approach)\n",
    "        #print(\"this is the scheme \",scheme)\n",
    "        time_index = tm_idx\n",
    "        \n",
    "        #each_flow_shortest_path = env.topology.get_each_flow_shortest_paths()\n",
    "        #each_flow_paths,each_path_id,each_id_path = self.get_each_flow_paths_and_path_id(env,config,topology_file)\n",
    "        each_flow_oblivious_paths = env.topology.get_each_flow_oblivious_paths(config.raeke_paths)\n",
    "        if scheme ==\"ECMP\":\n",
    "            \"\"\"for ECMP mlu\"\"\"\n",
    "            solutions = {}\n",
    "            ecmp_mlus = self.eval_ecmp_traffic_distribution2(tm_idx,look_ahead_window, eval_delay=eval_delay)\n",
    "            return ecmp_mlus,solutions,1,solutions\n",
    "        elif scheme ==\"Oblivious\":\n",
    "            \"\"\"for Oblivious routing\"\"\"\n",
    "            \n",
    "            each_flow_oblivious_paths_edges = env.topology.get_oblivious_paths_each_flow_edges(config.raeke_paths,\n",
    "                                                                                          max_move,self.each_flow_shortest_path)\n",
    "#             oblivious_mlus,oblivious_solutions = self.mlu_routing_selected_paths_oblivious(tm_idx,look_ahead_window,\n",
    "#                                                                              each_flow_oblivious_paths_edges)\n",
    "            oblivious_mlus,oblivious_solutions  = self.mlu_routing_selected_paths(tm_idx,look_ahead_window,\n",
    "                                                                   each_flow_oblivious_paths_edges)\n",
    "            solution = {}\n",
    "            return oblivious_mlus,oblivious_solutions,1,solution\n",
    "        elif scheme ==\"Oblivious2\":\n",
    "            \"\"\"for Oblivious routing\"\"\"\n",
    "            \n",
    "            each_flow_oblivious_paths_edges = env.topology.get_oblivious_paths_each_flow_edges(config.raeke_paths,\n",
    "                                                                                          max_move,self.each_flow_shortest_path)\n",
    "            oblivious_mlus,oblivious_solutions = self.mlu_routing_selected_paths_oblivious2(tm_idx,look_ahead_window,\n",
    "                                                                             each_flow_oblivious_paths_edges)\n",
    "            \n",
    "            oblivious_mlus,oblivious_solutions  = self.mlu_routing_selected_paths(tm_idx,look_ahead_window,\n",
    "                                                                   each_flow_oblivious_paths_edges)\n",
    "            solution = {}\n",
    "            return oblivious_mlus,oblivious_solutions,1,solution\n",
    "        elif scheme ==\"MLU-greedy\":\n",
    "            \"\"\"for MLU_greedy\"\"\"\n",
    "            time_index = tm_idx\n",
    "            mlu_greedy_mlus,mlu_greedy_solutions = self.mlu_optimal_routing_mlu(tm_idx,look_ahead_window)\n",
    "            #print(\"we have scheme %s and result is %s\"%(scheme,sum(mlu_greedy_mlus)/len(mlu_greedy_mlus)))\n",
    "            solution = {}\n",
    "            return mlu_greedy_mlus,mlu_greedy_solutions,1,solution\n",
    "        elif scheme==\"Optimal\":\n",
    "#             each_flow_all_paths,each_path_edges = self.get_set_of_all_paths(tm_idx,\n",
    "#                                                                                  look_ahead_window,each_flow_paths,\n",
    "#                                                                                  each_path_id,each_id_path,\n",
    "#                                                                                  each_flow_shortest_path,each_flow_oblivious_paths,\n",
    "#                                                                                  topology_file,config)\n",
    "            \n",
    "            \n",
    "            \n",
    "           \n",
    " \n",
    "           \n",
    "            import pdb\n",
    "            #pdb.set_trace()\n",
    "            optimal1_mlus,optimal1_solutions,optimal2_mlus,optimal2_solutions = self.optimal_solution_for_robust_paths(\n",
    "                                                                            tm_idx,look_ahead_window)\n",
    "        \n",
    "            return optimal1_mlus,optimal1_solutions,optimal2_mlus,optimal2_solutions\n",
    "        elif scheme ==\"DRL\":\n",
    "            \"\"\"for RL approach\"\"\"\n",
    "            time_index = tm_idx\n",
    "            max_move = len(actions)\n",
    "            each_flow_edges_rl_approach = self.get_suggested_paths_by_rl(actions)\n",
    "            \n",
    "#             each_flow_oblivious_paths_edges = env.topology.get_oblivious_paths_each_flow_edges(config.raeke_paths,\n",
    "#                                                                                           max_move,self.each_flow_shortest_path)\n",
    "            \n",
    "#             oblivious_max_node_number = []\n",
    "#             rl_max_node_number = []\n",
    "#             for flow,edges in each_flow_edges_rl_approach.items():\n",
    "#                 for edge in edges:\n",
    "#                     rl_max_node_number.append(edge[0])\n",
    "#                     rl_max_node_number.append(edge[1])\n",
    "#                 print(\"for flow %s we have edges in RL        %s \"%(flow,edges))\n",
    "#                 print(\"for flow %s we have edges in oblivious %s\"%(flow,each_flow_oblivious_paths_edges[flow]))\n",
    "#                 for edge in each_flow_oblivious_paths_edges[flow]:\n",
    "#                     oblivious_max_node_number.append(edge[0])\n",
    "#                     oblivious_max_node_number.append(edge[1])\n",
    "#                 if (len(each_flow_oblivious_paths_edges[flow])%2!=0):\n",
    "#                     print(\"error\")\n",
    "#             print(\"max rl %s max  oblivios %s\"%(max(rl_max_node_number),max(oblivious_max_node_number)))\n",
    "#             print(\"min rl %s min  oblivios %s\"%(min(rl_max_node_number),min(oblivious_max_node_number)))\n",
    "            #print(\"unique rl %s unique  oblivios %s\"%(len(list(set(rl_max_node_number))),len(list(set(oblivious_max_node_number)))))\n",
    "            actions.sort()\n",
    "#             for path in actions:\n",
    "#                 print(\"for DRL sceme we have %s path %s\"%(len(actions),path))\n",
    "            solution = {}\n",
    "            rl_mlus,rl_solutions = self.mlu_routing_selected_paths(tm_idx,look_ahead_window,\n",
    "                                                                   each_flow_edges_rl_approach)\n",
    "#             print(\"MLU using rl is \",sum(rl_mlus)/len(rl_mlus))\n",
    "#             for limit in [1,2,3,4,5,6,7,8,9,10,20,40,80,120,200,300,400,1000]:\n",
    "#                 backup_each_flow_edges_rl_approach = {}\n",
    "#                 for flow ,edges in each_flow_edges_rl_approach.items():\n",
    "#                     backup_each_flow_edges_rl_approach[flow] = edges\n",
    "#                 counter = 0\n",
    "#                 for edge in self.lp_links:\n",
    "#                     print(\"this is an edge \",edge)\n",
    "#                 for flow ,edges in each_flow_oblivious_paths_edges.items():\n",
    "#                     if flow != (0,3):\n",
    "#                         if counter <limit:\n",
    "#                             print(\"for flow \",flow)\n",
    "#                             #for edge in edges:\n",
    "#                             #    if edge not in each_flow_edges_rl_approach[flow]:\n",
    "#                             print(\"we replace this edges \",backup_each_flow_edges_rl_approach[flow])\n",
    "#                             print(\"with these \",edges)\n",
    "#                             backup_each_flow_edges_rl_approach[flow] = edges\n",
    "#                             for edge in edges:\n",
    "#                                 if edge not in self.lp_links:\n",
    "#                                     print(\"this is an ERROR!! link  does not exist in lp_links\",edge)\n",
    "#                             counter+=1\n",
    "#                 print(\"done adding edge to the default rl edges\",limit)\n",
    "#                 oblivious_mlus,oblivious_solutions  = self.mlu_routing_selected_paths(tm_idx,look_ahead_window,\n",
    "#                                                                        backup_each_flow_edges_rl_approach)\n",
    "\n",
    "#                 print(\"the mlu using oblivious is \",len(oblivious_mlus)/len(oblivious_mlus))\n",
    "#                 time.sleep(5)\n",
    "            return rl_mlus,rl_solutions,1,solution\n",
    "    \n",
    "        \n",
    "        \n",
    "                #print(\"oblivious edge flows\",len(list(each_flow_oblivious_paths_edges.keys())))\n",
    "        #print(\"shortest_paths\",len(list(each_flow_shortest_path.keys())))\n",
    "#         for flow,edges in each_flow_oblivious_paths_edges.items():\n",
    "#             print(\"flow %s has edges %s\"%(flow,edges))\n",
    "        \n",
    "\n",
    "    \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "                \n",
    "        \n",
    "#         each_flow_all_paths,each_path_edges = self.get_set_of_all_paths(tm_idx,\n",
    "#                                                                              look_ahead_window,each_flow_paths,\n",
    "#                                                                              each_path_id,each_id_path,\n",
    "#                                                                              each_flow_shortest_path,each_flow_oblivious_paths,topology_file,config)\n",
    "        \n",
    "#         hindsight_mlus,hindsight_solutions = self.optimal_solution_for_robust_paths(tm_idx,look_ahead_window,\n",
    "#                                                                              each_flow_all_paths,each_path_edges)\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "#         if sum(oblivious_mlus)/len(oblivious_mlus) < sum(hindsight_mlus)/len(hindsight_mlus):\n",
    "#             hindsight_mlus,hindsight_solutions = self.mlu_routing_selected_paths(tm_idx,look_ahead_window,\n",
    "#                                                                              each_flow_oblivious_paths_edges)\n",
    "        \n",
    "        \n",
    "        \n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "      \n",
    "       \n",
    "        \n",
    "\n",
    "        \n",
    "                \n",
    "                \n",
    "                "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
